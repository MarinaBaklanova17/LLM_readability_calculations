{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc\n",
        "\n"
      ],
      "metadata": {
        "id": "T3rjjYOwqgZh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CRMalgSq2xZ",
        "outputId": "b5f4284a-8913-4242-df6b-ab031e91c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qeIAt6GqM-V",
        "outputId": "17ee41e3-f1f6-486b-d313-dbbce33000c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              sum_sq     df         F    PR(>F)\n",
            "C(model)  225.937579   28.0  2.768547  0.000012\n",
            "Residual  798.599714  274.0       NaN       NaN\n",
            "            group1                         group2  meandiff   p-adj   lower  \\\n",
            "405  original_text  qwen-2-72b-instruct@deepinfra    2.5371  0.0232  0.1439   \n",
            "\n",
            "      upper  reject  \n",
            "405  4.9304    True  \n"
          ]
        }
      ],
      "source": [
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "control_group = filtered_df[filtered_df['model'] == 'original_text']\n",
        "other_groups = filtered_df[filtered_df['model'] != 'original_text']\n",
        "\n",
        "combined_df = pd.concat([control_group, other_groups])\n",
        "\n",
        "model = ols('Q(\"Automated Readability Index\") ~ C(model)', data=combined_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "\n",
        "# Tukey's HSD test\n",
        "comp = mc.pairwise_tukeyhsd(combined_df['Automated Readability Index'], combined_df['model'])\n",
        "tukey_results = pd.DataFrame(data=comp.summary().data[1:], columns=comp.summary().data[0])\n",
        "\n",
        "control_comparisons = tukey_results[tukey_results['group1'] == 'original_text']\n",
        "\n",
        "# Sort by absolute mean difference to find the most similar models\n",
        "control_comparisons_sorted = control_comparisons.sort_values(by='meandiff', key=abs)\n",
        "print(control_comparisons_sorted.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\",\n",
        "    \"nemotron-4-340b-instruct@deepinfra\",\n",
        "    \"codellama-13b-instruct@together-ai\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "# summary table for the 'Flesch Reading Ease' grouped by 'model'\n",
        "summary_table = filtered_df.groupby('model')['Automated Readability Index'].describe()\n",
        "\n",
        "print(summary_table)\n",
        "\n",
        "# Define and fit the ANOVA model\n",
        "model = ols('Q(\"Automated Readability Index\") ~ C(model)', data=filtered_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYFKiKfsqo3C",
        "outputId": "c0b2d7c0-6048-477c-d452-e1e580849901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        count       mean       std   min  \\\n",
            "model                                                                      \n",
            "claude-3-haiku@anthropic                 15.0   9.020000  1.558937   6.5   \n",
            "claude-3-opus@anthropic                  15.0   8.906667  1.864889   5.9   \n",
            "claude-3-sonnet@anthropic                 1.0  12.600000       NaN  12.6   \n",
            "claude-3.5-sonnet@anthropic              15.0   8.353333  1.380924   5.5   \n",
            "gemini-1.5-flash@vertex-ai               15.0   8.653333  1.428719   6.5   \n",
            "gemini-1.5-pro@vertex-ai                 15.0   8.206667  0.982320   6.8   \n",
            "gemma-2-9b-it@fireworks-ai               15.0   8.906667  1.685428   6.0   \n",
            "gemma-2b-it@together-ai                  14.0   9.335714  2.016321   6.2   \n",
            "gemma-7b-it@anyscale                      1.0  10.100000       NaN  10.1   \n",
            "gpt-3.5-turbo@openai                     15.0   9.693333  1.568196   6.9   \n",
            "gpt-4-turbo@openai                       15.0   8.853333  1.417678   6.1   \n",
            "gpt-4@openai                             15.0   7.833333  1.187835   5.5   \n",
            "gpt-4o@openai                            15.0   7.953333  1.177689   6.2   \n",
            "llama-3-70b-chat@anyscale                 1.0  12.400000       NaN  12.4   \n",
            "llama-3-70b-chat@fireworks-ai            14.0  10.600000  1.835965   7.6   \n",
            "llama-3-8b-chat@anyscale                  1.0   9.600000       NaN   9.6   \n",
            "llama-3-8b-chat@fireworks-ai             14.0   9.985714  2.607344   5.4   \n",
            "mistral-7b-instruct-v0.1@anyscale         1.0   8.500000       NaN   8.5   \n",
            "mistral-7b-instruct-v0.3@together-ai     15.0   9.813333  1.411618   7.0   \n",
            "mistral-large@aws-bedrock                15.0   9.206667  1.592602   6.0   \n",
            "mistral-small@mistral-ai                 15.0   8.193333  1.142345   6.4   \n",
            "mixtral-8x22b-instruct-v0.1@anyscale      1.0   9.700000       NaN   9.7   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    14.0   8.371429  1.368002   6.2   \n",
            "mixtral-8x7b-instruct-v0.1@anyscale       1.0   8.600000       NaN   8.6   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   14.0   8.421429  1.499322   5.2   \n",
            "original_text                            15.0   8.220000  3.483881   3.8   \n",
            "qwen-2-72b-instruct@deepinfra            14.0  10.757143  1.088198   8.6   \n",
            "\n",
            "                                           25%    50%     75%   max  \n",
            "model                                                                \n",
            "claude-3-haiku@anthropic                 8.250   8.80  10.450  10.9  \n",
            "claude-3-opus@anthropic                  7.550   8.90   9.600  13.3  \n",
            "claude-3-sonnet@anthropic               12.600  12.60  12.600  12.6  \n",
            "claude-3.5-sonnet@anthropic              7.350   8.70   9.300  10.2  \n",
            "gemini-1.5-flash@vertex-ai               7.500   8.10   9.900  11.3  \n",
            "gemini-1.5-pro@vertex-ai                 7.450   8.40   8.500  10.4  \n",
            "gemma-2-9b-it@fireworks-ai               7.800   8.90   9.800  11.9  \n",
            "gemma-2b-it@together-ai                  7.425   9.85  11.050  11.7  \n",
            "gemma-7b-it@anyscale                    10.100  10.10  10.100  10.1  \n",
            "gpt-3.5-turbo@openai                     9.000   9.60  10.450  12.8  \n",
            "gpt-4-turbo@openai                       8.000   8.90  10.000  11.1  \n",
            "gpt-4@openai                             7.100   7.80   8.550   9.9  \n",
            "gpt-4o@openai                            7.000   7.90   8.700  10.3  \n",
            "llama-3-70b-chat@anyscale               12.400  12.40  12.400  12.4  \n",
            "llama-3-70b-chat@fireworks-ai            9.450  10.50  11.800  14.8  \n",
            "llama-3-8b-chat@anyscale                 9.600   9.60   9.600   9.6  \n",
            "llama-3-8b-chat@fireworks-ai             8.250   9.70  12.175  13.8  \n",
            "mistral-7b-instruct-v0.1@anyscale        8.500   8.50   8.500   8.5  \n",
            "mistral-7b-instruct-v0.3@together-ai     9.200   9.80  10.500  13.3  \n",
            "mistral-large@aws-bedrock                7.800   9.90  10.450  11.0  \n",
            "mistral-small@mistral-ai                 7.450   8.10   9.050  10.3  \n",
            "mixtral-8x22b-instruct-v0.1@anyscale     9.700   9.70   9.700   9.7  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    7.125   8.45   9.625  10.1  \n",
            "mixtral-8x7b-instruct-v0.1@anyscale      8.600   8.60   8.600   8.6  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   7.575   8.55   9.425  10.6  \n",
            "original_text                            5.850   7.70  10.000  15.5  \n",
            "qwen-2-72b-instruct@deepinfra           10.025  10.85  11.150  12.7  \n",
            "              sum_sq     df        F    PR(>F)\n",
            "C(model)  222.962346   26.0  2.94225  0.000006\n",
            "Residual  798.599714  274.0      NaN       NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "anova_df = pd.DataFrame(anova_table)\n",
        "\n",
        "output_file = 'anova_table_output_Automated Readability Index.xlsx'\n",
        "\n",
        "anova_df.to_excel(output_file, index=True)\n",
        "\n",
        "print(f\"ANOVA table saved as {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4MvO3GZq-Ut",
        "outputId": "8e37cd77-18bd-45d3-ca19-11cc4aa401e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANOVA table saved as anova_table_output_Automated Readability Index.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_table = filtered_df.groupby('model')['Automated Readability Index'].describe()\n",
        "anova_df = pd.DataFrame(anova_table)\n",
        "\n",
        "output_file_path = 'summary_and_anova_output_Automated Readability Index.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
        "    summary_table.to_excel(writer, sheet_name='Summary Statistics')\n",
        "    anova_df.to_excel(writer, sheet_name='ANOVA Table')\n",
        "\n",
        "print(f\"Data has been saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8I1wwXmrScP",
        "outputId": "e29ae43c-0d69-4e5c-835a-1b5199e2570b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to summary_and_anova_output_Automated Readability Index.xlsx\n"
          ]
        }
      ]
    }
  ]
}