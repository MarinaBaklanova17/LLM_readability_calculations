{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7w2MLmfqaGm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165TGSKNqkre",
        "outputId": "02c6f00c-6cab-446e-ff8e-147c71428472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "control_group = filtered_df[filtered_df['model'] == 'original_text']\n",
        "other_groups = filtered_df[filtered_df['model'] != 'original_text']\n",
        "combined_df = pd.concat([control_group, other_groups])\n",
        "\n",
        "model = ols('Q(\"SMOG Index\") ~ C(model)', data=combined_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "\n",
        "# Tukey's HSD test\n",
        "comp = mc.pairwise_tukeyhsd(combined_df['SMOG Index'], combined_df['model'])\n",
        "tukey_results = pd.DataFrame(data=comp.summary().data[1:], columns=comp.summary().data[0])\n",
        "\n",
        "control_comparisons = tukey_results[tukey_results['group1'] == 'original_text']\n",
        "\n",
        "# Sort by absolute mean difference to find the most similar models\n",
        "control_comparisons_sorted = control_comparisons.sort_values(by='meandiff', key=abs)\n",
        "print(control_comparisons_sorted.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzchz-z4qpZP",
        "outputId": "76938b6b-0f28-44f7-a002-1b17b348799a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              sum_sq     df         F        PR(>F)\n",
            "C(model)  187.488403   28.0  4.291898  1.050151e-10\n",
            "Residual  427.481762  274.0       NaN           NaN\n",
            "            group1                         group2  meandiff  p-adj   lower  \\\n",
            "405  original_text  qwen-2-72b-instruct@deepinfra    3.5957    0.0  1.8447   \n",
            "\n",
            "      upper  reject  \n",
            "405  5.3467    True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\",\n",
        "    \"nemotron-4-340b-instruct@deepinfra\",\n",
        "    \"codellama-13b-instruct@together-ai\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "summary_table = filtered_df.groupby('model')['SMOG Index'].describe()\n",
        "\n",
        "print(summary_table)\n",
        "model = ols('Q(\"SMOG Index\") ~ C(model)', data=filtered_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdjjMQXx33hA",
        "outputId": "eb71b9e9-1706-427e-974a-f0af469ec7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        count       mean       std   min  \\\n",
            "model                                                                      \n",
            "claude-3-haiku@anthropic                 15.0   9.220000  1.081137   7.4   \n",
            "claude-3-opus@anthropic                  15.0   9.126667  1.181081   6.9   \n",
            "claude-3-sonnet@anthropic                 1.0  11.400000       NaN  11.4   \n",
            "claude-3.5-sonnet@anthropic              15.0   8.846667  1.128758   6.4   \n",
            "gemini-1.5-flash@vertex-ai               15.0   8.733333  1.119098   6.8   \n",
            "gemini-1.5-pro@vertex-ai                 15.0   8.433333  0.718795   7.4   \n",
            "gemma-2-9b-it@fireworks-ai               15.0   8.533333  1.211650   6.2   \n",
            "gemma-2b-it@together-ai                  14.0   9.207143  1.219372   7.1   \n",
            "gemma-7b-it@anyscale                      1.0  10.100000       NaN  10.1   \n",
            "gpt-3.5-turbo@openai                     15.0   9.300000  1.281740   7.7   \n",
            "gpt-4-turbo@openai                       15.0   8.293333  0.786917   6.9   \n",
            "gpt-4@openai                             15.0   8.813333  0.896714   7.6   \n",
            "gpt-4o@openai                            15.0   8.586667  0.709997   7.5   \n",
            "llama-3-70b-chat@anyscale                 1.0  11.300000       NaN  11.3   \n",
            "llama-3-70b-chat@fireworks-ai            14.0   9.557143  1.251900   7.6   \n",
            "llama-3-8b-chat@anyscale                  1.0   9.100000       NaN   9.1   \n",
            "llama-3-8b-chat@fireworks-ai             14.0   9.507143  1.464169   7.0   \n",
            "mistral-7b-instruct-v0.1@anyscale         1.0  10.200000       NaN  10.2   \n",
            "mistral-7b-instruct-v0.3@together-ai     15.0   9.633333  1.217531   7.0   \n",
            "mistral-large@aws-bedrock                15.0   9.346667  0.879827   8.0   \n",
            "mistral-small@mistral-ai                 15.0   8.720000  1.095576   6.8   \n",
            "mixtral-8x22b-instruct-v0.1@anyscale      1.0   8.800000       NaN   8.8   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    14.0   8.942857  0.676773   7.9   \n",
            "mixtral-8x7b-instruct-v0.1@anyscale       1.0   9.700000       NaN   9.7   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   14.0   7.985714  2.523995   0.0   \n",
            "original_text                            15.0   6.340000  2.152009   3.1   \n",
            "qwen-2-72b-instruct@deepinfra            14.0   9.935714  0.826119   8.5   \n",
            "\n",
            "                                           25%    50%     75%   max  \n",
            "model                                                                \n",
            "claude-3-haiku@anthropic                 8.550   9.10  10.200  10.8  \n",
            "claude-3-opus@anthropic                  8.500   9.00   9.800  11.9  \n",
            "claude-3-sonnet@anthropic               11.400  11.40  11.400  11.4  \n",
            "claude-3.5-sonnet@anthropic              8.100   8.80   9.600  10.6  \n",
            "gemini-1.5-flash@vertex-ai               8.050   8.50   9.600  10.9  \n",
            "gemini-1.5-pro@vertex-ai                 7.950   8.40   8.950   9.6  \n",
            "gemma-2-9b-it@fireworks-ai               7.800   8.60   8.900  10.9  \n",
            "gemma-2b-it@together-ai                  8.525   9.75  10.175  10.4  \n",
            "gemma-7b-it@anyscale                    10.100  10.10  10.100  10.1  \n",
            "gpt-3.5-turbo@openai                     8.300   9.20   9.900  12.2  \n",
            "gpt-4-turbo@openai                       7.750   8.20   8.650   9.8  \n",
            "gpt-4@openai                             8.250   8.80   9.100  11.0  \n",
            "gpt-4o@openai                            8.050   8.70   9.000   9.9  \n",
            "llama-3-70b-chat@anyscale               11.300  11.30  11.300  11.3  \n",
            "llama-3-70b-chat@fireworks-ai            8.725   9.40  10.075  11.8  \n",
            "llama-3-8b-chat@anyscale                 9.100   9.10   9.100   9.1  \n",
            "llama-3-8b-chat@fireworks-ai             8.650   9.45  10.100  12.4  \n",
            "mistral-7b-instruct-v0.1@anyscale       10.200  10.20  10.200  10.2  \n",
            "mistral-7b-instruct-v0.3@together-ai     8.900   9.80  10.400  11.4  \n",
            "mistral-large@aws-bedrock                8.600   9.70   9.800  10.9  \n",
            "mistral-small@mistral-ai                 7.800   8.80   9.450  10.8  \n",
            "mixtral-8x22b-instruct-v0.1@anyscale     8.800   8.80   8.800   8.8  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    8.475   8.95   9.500  10.0  \n",
            "mixtral-8x7b-instruct-v0.1@anyscale      9.700   9.70   9.700   9.7  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   7.800   8.45   9.175  11.0  \n",
            "original_text                            5.500   7.00   7.350  11.2  \n",
            "qwen-2-72b-instruct@deepinfra            9.550   9.85  10.300  12.1  \n",
            "              sum_sq     df         F        PR(>F)\n",
            "C(model)  182.321361   26.0  4.494663  7.404427e-11\n",
            "Residual  427.481762  274.0       NaN           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc\n",
        "\n",
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\",\n",
        "    \"nemotron-4-340b-instruct@deepinfra\",\n",
        "    \"codellama-13b-instruct@together-ai\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['SMOG Index'].describe()\n",
        "\n",
        "\n",
        "print(summary_table)\n",
        "model = ols('Q(\"SMOG Index\") ~ C(model)', data=filtered_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "anova_table.to_excel('anova_table_SMOG Indexx.xlsx', index=True)\n",
        "\n",
        "# Tukey's HSD test to compare differences between groups\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['SMOG Index'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_SMOG Index.xlsx', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoEAYIIlQvAZ",
        "outputId": "7e577b39-4d17-475d-8dac-1345d96b1d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        count       mean       std   min  \\\n",
            "model                                                                      \n",
            "claude-3-haiku@anthropic                 15.0   9.220000  1.081137   7.4   \n",
            "claude-3-opus@anthropic                  15.0   9.126667  1.181081   6.9   \n",
            "claude-3-sonnet@anthropic                 1.0  11.400000       NaN  11.4   \n",
            "claude-3.5-sonnet@anthropic              15.0   8.846667  1.128758   6.4   \n",
            "gemini-1.5-flash@vertex-ai               15.0   8.733333  1.119098   6.8   \n",
            "gemini-1.5-pro@vertex-ai                 15.0   8.433333  0.718795   7.4   \n",
            "gemma-2-9b-it@fireworks-ai               15.0   8.533333  1.211650   6.2   \n",
            "gemma-2b-it@together-ai                  14.0   9.207143  1.219372   7.1   \n",
            "gemma-7b-it@anyscale                      1.0  10.100000       NaN  10.1   \n",
            "gpt-3.5-turbo@openai                     15.0   9.300000  1.281740   7.7   \n",
            "gpt-4-turbo@openai                       15.0   8.293333  0.786917   6.9   \n",
            "gpt-4@openai                             15.0   8.813333  0.896714   7.6   \n",
            "gpt-4o@openai                            15.0   8.586667  0.709997   7.5   \n",
            "llama-3-70b-chat@anyscale                 1.0  11.300000       NaN  11.3   \n",
            "llama-3-70b-chat@fireworks-ai            14.0   9.557143  1.251900   7.6   \n",
            "llama-3-8b-chat@anyscale                  1.0   9.100000       NaN   9.1   \n",
            "llama-3-8b-chat@fireworks-ai             14.0   9.507143  1.464169   7.0   \n",
            "mistral-7b-instruct-v0.1@anyscale         1.0  10.200000       NaN  10.2   \n",
            "mistral-7b-instruct-v0.3@together-ai     15.0   9.633333  1.217531   7.0   \n",
            "mistral-large@aws-bedrock                15.0   9.346667  0.879827   8.0   \n",
            "mistral-small@mistral-ai                 15.0   8.720000  1.095576   6.8   \n",
            "mixtral-8x22b-instruct-v0.1@anyscale      1.0   8.800000       NaN   8.8   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    14.0   8.942857  0.676773   7.9   \n",
            "mixtral-8x7b-instruct-v0.1@anyscale       1.0   9.700000       NaN   9.7   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   14.0   7.985714  2.523995   0.0   \n",
            "original_text                            15.0   6.340000  2.152009   3.1   \n",
            "qwen-2-72b-instruct@deepinfra            14.0   9.935714  0.826119   8.5   \n",
            "\n",
            "                                           25%    50%     75%   max  \n",
            "model                                                                \n",
            "claude-3-haiku@anthropic                 8.550   9.10  10.200  10.8  \n",
            "claude-3-opus@anthropic                  8.500   9.00   9.800  11.9  \n",
            "claude-3-sonnet@anthropic               11.400  11.40  11.400  11.4  \n",
            "claude-3.5-sonnet@anthropic              8.100   8.80   9.600  10.6  \n",
            "gemini-1.5-flash@vertex-ai               8.050   8.50   9.600  10.9  \n",
            "gemini-1.5-pro@vertex-ai                 7.950   8.40   8.950   9.6  \n",
            "gemma-2-9b-it@fireworks-ai               7.800   8.60   8.900  10.9  \n",
            "gemma-2b-it@together-ai                  8.525   9.75  10.175  10.4  \n",
            "gemma-7b-it@anyscale                    10.100  10.10  10.100  10.1  \n",
            "gpt-3.5-turbo@openai                     8.300   9.20   9.900  12.2  \n",
            "gpt-4-turbo@openai                       7.750   8.20   8.650   9.8  \n",
            "gpt-4@openai                             8.250   8.80   9.100  11.0  \n",
            "gpt-4o@openai                            8.050   8.70   9.000   9.9  \n",
            "llama-3-70b-chat@anyscale               11.300  11.30  11.300  11.3  \n",
            "llama-3-70b-chat@fireworks-ai            8.725   9.40  10.075  11.8  \n",
            "llama-3-8b-chat@anyscale                 9.100   9.10   9.100   9.1  \n",
            "llama-3-8b-chat@fireworks-ai             8.650   9.45  10.100  12.4  \n",
            "mistral-7b-instruct-v0.1@anyscale       10.200  10.20  10.200  10.2  \n",
            "mistral-7b-instruct-v0.3@together-ai     8.900   9.80  10.400  11.4  \n",
            "mistral-large@aws-bedrock                8.600   9.70   9.800  10.9  \n",
            "mistral-small@mistral-ai                 7.800   8.80   9.450  10.8  \n",
            "mixtral-8x22b-instruct-v0.1@anyscale     8.800   8.80   8.800   8.8  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    8.475   8.95   9.500  10.0  \n",
            "mixtral-8x7b-instruct-v0.1@anyscale      9.700   9.70   9.700   9.7  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   7.800   8.45   9.175  11.0  \n",
            "original_text                            5.500   7.00   7.350  11.2  \n",
            "qwen-2-72b-instruct@deepinfra            9.550   9.85  10.300  12.1  \n",
            "              sum_sq     df         F        PR(>F)\n",
            "C(model)  182.321361   26.0  4.494663  7.404427e-11\n",
            "Residual  427.481762  274.0       NaN           NaN\n",
            "                                Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic  -0.0933    1.0 -1.7972  1.6106  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic     2.18 0.9959 -2.6393  6.9993  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic  -0.3733    1.0 -2.0772  1.3306  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai  -0.4867    1.0 -2.1906  1.2172  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai  -0.7867 0.9945 -2.4906  0.9172  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai  -0.6867 0.9993 -2.3906  1.0172  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai  -0.0129    1.0 -1.7469  1.7212  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale     0.88    1.0 -3.9393  5.6993  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai     0.08    1.0 -1.6239  1.7839  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai  -0.9267 0.9568 -2.6306  0.7772  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai  -0.4067    1.0 -2.1106  1.2972  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai  -0.6333 0.9998 -2.3372  1.0706  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale     2.08  0.998 -2.7393  6.8993  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai   0.3371    1.0 -1.3969  2.0712  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale    -0.12    1.0 -4.9393  4.6993  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai   0.2871    1.0 -1.4469  2.0212  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale     0.98    1.0 -3.8393  5.7993  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai   0.4133    1.0 -1.2906  2.1172  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock   0.1267    1.0 -1.5772  1.8306  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai     -0.5    1.0 -2.2039  1.2039  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale    -0.42    1.0 -5.2393  4.3993  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.2771    1.0 -2.0112  1.4569  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     0.48    1.0 -4.3393  5.2993  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2343 0.6093 -2.9683  0.4998  False\n",
            "              claude-3-haiku@anthropic                          original_text    -2.88    0.0 -4.5839 -1.1761   True\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra   0.7157  0.999 -1.0183  2.4498  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic   2.2733 0.9926  -2.546  7.0927  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic    -0.28    1.0 -1.9839  1.4239  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai  -0.3933    1.0 -2.0972  1.3106  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai  -0.6933 0.9992 -2.3972  1.0106  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai  -0.5933 0.9999 -2.2972  1.1106  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai   0.0805    1.0 -1.6536  1.8145  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale   0.9733    1.0  -3.846  5.7927  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai   0.1733    1.0 -1.5306  1.8772  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai  -0.8333  0.988 -2.5372  0.8706  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai  -0.3133    1.0 -2.0172  1.3906  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai    -0.54    1.0 -2.2439  1.1639  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale   2.1733 0.9961  -2.646  6.9927  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai   0.4305    1.0 -1.3036  2.1645  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale  -0.0267    1.0  -4.846  4.7927  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai   0.3805    1.0 -1.3536  2.1145  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale   1.0733    1.0  -3.746  5.8927  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5067    1.0 -1.1972  2.2106  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock     0.22    1.0 -1.4839  1.9239  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai  -0.4067    1.0 -2.1106  1.2972  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale  -0.3267    1.0  -5.146  4.4927  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.1838    1.0 -1.9179  1.5502  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   0.5733    1.0  -4.246  5.3927  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   -1.141 0.7599  -2.875  0.5931  False\n",
            "               claude-3-opus@anthropic                          original_text  -2.7867    0.0 -4.4906 -1.0828   True\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra    0.809 0.9937  -0.925  2.5431  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  -2.5533 0.9678 -7.3727   2.266  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -2.6667  0.948  -7.486  2.1527  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -2.9667 0.8563  -7.786  1.8527  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  -2.8667 0.8936  -7.686  1.9527  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai  -2.1929 0.9957  -7.023  2.6372  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale     -1.3    1.0 -7.8992  5.2992  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai     -2.1 0.9977 -6.9193  2.7193  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  -3.1067 0.7929  -7.926  1.7127  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai  -2.5867 0.9627  -7.406  2.2327  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  -2.8133 0.9107 -7.6327   2.006  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale     -0.1    1.0 -6.6992  6.4992  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai  -1.8429 0.9997  -6.673  2.9872  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale     -2.3 0.9999 -8.8992  4.2992  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai  -1.8929 0.9996  -6.723  2.9372  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale     -1.2    1.0 -7.7992  5.3992  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai  -1.7667 0.9999  -6.586  3.0527  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock  -2.0533 0.9983 -6.8727   2.766  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai    -2.68 0.9451 -7.4993  2.1393  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     -2.6 0.9995 -9.1992  3.9992  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -2.4571 0.9802 -7.2872   2.373  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     -1.7    1.0 -8.2992  4.8992  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.4143 0.6238 -8.2444  1.4158  False\n",
            "             claude-3-sonnet@anthropic                          original_text    -5.06 0.0268 -9.8793 -0.2407   True\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra  -1.4643    1.0 -6.2944  3.3658  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -0.1133    1.0 -1.8172  1.5906  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -0.4133    1.0 -2.1172  1.2906  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  -0.3133    1.0 -2.0172  1.3906  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai   0.3605    1.0 -1.3736  2.0945  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale   1.2533    1.0  -3.566  6.0727  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai   0.4533    1.0 -1.2506  2.1572  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai  -0.5533    1.0 -2.2572  1.1506  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai  -0.0333    1.0 -1.7372  1.6706  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai    -0.26    1.0 -1.9639  1.4439  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale   2.4533   0.98  -2.366  7.2727  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai   0.7105 0.9991 -1.0236  2.4445  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale   0.2533    1.0  -4.566  5.0727  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   0.6605 0.9997 -1.0736  2.3945  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale   1.3533    1.0  -3.466  6.1727  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai   0.7867 0.9945 -0.9172  2.4906  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock      0.5    1.0 -1.2039  2.2039  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai  -0.1267    1.0 -1.8306  1.5772  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale  -0.0467    1.0  -4.866  4.7727  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra   0.0962    1.0 -1.6379  1.8302  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   0.8533    1.0  -3.966  5.6727  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.861 0.9854  -2.595  0.8731  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text  -2.5067    0.0 -4.2106 -0.8028   True\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra    1.089 0.8306  -0.645  2.8231  False\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai     -0.3    1.0 -2.0039  1.4039  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai     -0.2    1.0 -1.9039  1.5039  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai   0.4738    1.0 -1.2602  2.2079  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale   1.3667    1.0 -3.4527   6.186  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai   0.5667    1.0 -1.1372  2.2706  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai    -0.44    1.0 -2.1439  1.2639  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai     0.08    1.0 -1.6239  1.7839  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai  -0.1467    1.0 -1.8506  1.5572  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale   2.5667 0.9659 -2.2527   7.386  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai   0.8238 0.9919 -0.9102  2.5579  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale   0.3667    1.0 -4.4527   5.186  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai   0.7738 0.9967 -0.9602  2.5079  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.4667    1.0 -3.3527   6.286  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai      0.9  0.969 -0.8039  2.6039  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock   0.6133 0.9999 -1.0906  2.3172  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai  -0.0133    1.0 -1.7172  1.6906  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.0667    1.0 -4.7527   4.886  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.2095    1.0 -1.5245  1.9436  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.9667    1.0 -3.8527   5.786  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.7476  0.998 -2.4817  0.9864  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text  -2.3933 0.0001 -4.0972 -0.6894   True\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra   1.2024 0.6631 -0.5317  2.9364  False\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai      0.1    1.0 -1.6039  1.8039  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai   0.7738 0.9967 -0.9602  2.5079  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale   1.6667    1.0 -3.1527   6.486  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai   0.8667 0.9802 -0.8372  2.5706  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai    -0.14    1.0 -1.8439  1.5639  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai     0.38    1.0 -1.3239  2.0839  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai   0.1533    1.0 -1.5506  1.8572  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale   2.8667 0.8936 -1.9527   7.686  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai   1.1238 0.7845 -0.6102  2.8579  False\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale   0.6667    1.0 -4.1527   5.486  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai   1.0738 0.8489 -0.6602  2.8079  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.7667 0.9999 -3.0527   6.586  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai      1.2 0.6314 -0.5039  2.9039  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock   0.9133 0.9633 -0.7906  2.6172  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai   0.2867    1.0 -1.4172  1.9906  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.3667    1.0 -4.4527   5.186  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.5095    1.0 -1.2245  2.2436  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.2667    1.0 -3.5527   6.086  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4476    1.0 -2.1817  1.2864  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text  -2.0933  0.002 -3.7972 -0.3894   True\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra   1.5024 0.2061 -0.2317  3.2364  False\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai   0.6738 0.9996 -1.0602  2.4079  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale   1.5667    1.0 -3.2527   6.386  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai   0.7667 0.9962 -0.9372  2.4706  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai    -0.24    1.0 -1.9439  1.4639  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai     0.28    1.0 -1.4239  1.9839  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai   0.0533    1.0 -1.6506  1.7572  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale   2.7667 0.9241 -2.0527   7.586  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai   1.0238 0.9006 -0.7102  2.7579  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale   0.5667    1.0 -4.2527   5.386  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai   0.9738 0.9392 -0.7602  2.7079  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   1.6667    1.0 -3.1527   6.486  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai      1.1 0.7906 -0.6039  2.8039  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock   0.8133 0.9913 -0.8906  2.5172  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai   0.1867    1.0 -1.5172  1.8906  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.2667    1.0 -4.5527   5.086  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.4095    1.0 -1.3245  2.1436  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.1667    1.0 -3.6527   5.986  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.5476    1.0 -2.2817  1.1864  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text  -2.1933 0.0008 -3.8972 -0.4894   True\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra   1.4024 0.3331 -0.3317  3.1364  False\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale   0.8929    1.0 -3.9372   5.723  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai   0.0929    1.0 -1.6412  1.8269  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai  -0.9138 0.9698 -2.6479  0.8202  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai  -0.3938    1.0 -2.1279  1.3402  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai  -0.6205 0.9999 -2.3545  1.1136  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale   2.0929 0.9979 -2.7372   6.923  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai     0.35    1.0 -1.4137  2.1137  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale  -0.1071    1.0 -4.9372   4.723  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai      0.3    1.0 -1.4637  2.0637  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale   0.9929    1.0 -3.8372   5.823  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai   0.4262    1.0 -1.3079  2.1602  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock   0.1395    1.0 -1.5945  1.8736  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai  -0.4871    1.0 -2.2212  1.2469  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.4071    1.0 -5.2372   4.423  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.2643    1.0  -2.028  1.4994  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.4929    1.0 -4.3372   5.323  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2214 0.6655 -2.9851  0.5423  False\n",
            "               gemma-2b-it@together-ai                          original_text  -2.8671    0.0 -4.6012 -1.1331   True\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra   0.7286  0.999 -1.0351  2.4923  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai     -0.8    1.0 -5.6193  4.0193  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  -1.8067 0.9998  -6.626  3.0127  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai  -1.2867    1.0  -6.106  3.5327  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  -1.5133    1.0 -6.3327   3.306  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale      1.2    1.0 -5.3992  7.7992  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai  -0.5429    1.0  -5.373  4.2872  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale     -1.0    1.0 -7.5992  5.5992  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai  -0.5929    1.0  -5.423  4.2372  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale      0.1    1.0 -6.4992  6.6992  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.4667    1.0  -5.286  4.3527  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  -0.7533    1.0 -5.5727   4.066  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai    -1.38    1.0 -6.1993  3.4393  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -1.3    1.0 -7.8992  5.2992  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.1571    1.0 -5.9872   3.673  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.4    1.0 -6.9992  6.1992  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.1143 0.9975 -6.9444  2.7158  False\n",
            "                  gemma-7b-it@anyscale                          original_text    -3.76 0.4089 -8.5793  1.0593  False\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra  -0.1643    1.0 -4.9944  4.6658  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai  -1.0067    0.9 -2.7106  0.6972  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai  -0.4867    1.0 -2.1906  1.2172  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai  -0.7133 0.9987 -2.4172  0.9906  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale      2.0 0.9989 -2.8193  6.8193  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai   0.2571    1.0 -1.4769  1.9912  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale     -0.2    1.0 -5.0193  4.6193  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai   0.2071    1.0 -1.5269  1.9412  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale      0.9    1.0 -3.9193  5.7193  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai   0.3333    1.0 -1.3706  2.0372  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock   0.0467    1.0 -1.6572  1.7506  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai    -0.58    1.0 -2.2839  1.1239  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale     -0.5    1.0 -5.3193  4.3193  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.3571    1.0 -2.0912  1.3769  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale      0.4    1.0 -4.4193  5.2193  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3143 0.4724 -3.0483  0.4198  False\n",
            "                  gpt-3.5-turbo@openai                          original_text    -2.96    0.0 -4.6639 -1.2561   True\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra   0.6357 0.9999 -1.0983  2.3698  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai     0.52    1.0 -1.1839  2.2239  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai   0.2933    1.0 -1.4106  1.9972  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale   3.0067 0.8394 -1.8127   7.826  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai   1.2638 0.5586 -0.4702  2.9979  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale   0.8067    1.0 -4.0127   5.626  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai   1.2138  0.644 -0.5202  2.9479  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale   1.9067 0.9995 -2.9127   6.726  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai     1.34 0.3917 -0.3639  3.0439  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock   1.0533 0.8511 -0.6506  2.7572  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai   0.4267    1.0 -1.2772  2.1306  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.5067    1.0 -4.3127   5.326  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.6495 0.9998 -1.0845  2.3836  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.4067    1.0 -3.4127   6.226  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.3076    1.0 -2.0417  1.4264  False\n",
            "                    gpt-4-turbo@openai                          original_text  -1.9533 0.0071 -3.6572 -0.2494   True\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   1.6424 0.0918 -0.0917  3.3764  False\n",
            "                          gpt-4@openai                          gpt-4o@openai  -0.2267    1.0 -1.9306  1.4772  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale   2.4867 0.9765 -2.3327   7.306  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai   0.7438 0.9982 -0.9902  2.4779  False\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale   0.2867    1.0 -4.5327   5.106  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai   0.6938 0.9994 -1.0402  2.4279  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale   1.3867    1.0 -3.4327   6.206  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai     0.82 0.9903 -0.8839  2.5239  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock   0.5333    1.0 -1.1706  2.2372  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai  -0.0933    1.0 -1.7972  1.6106  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale  -0.0133    1.0 -4.8327   4.806  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.1295    1.0 -1.6045  1.8636  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale   0.8867    1.0 -3.9327   5.706  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.8276 0.9913 -2.5617  0.9064  False\n",
            "                          gpt-4@openai                          original_text  -2.4733    0.0 -4.1772 -0.7694   True\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra   1.1224 0.7866 -0.6117  2.8564  False\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale   2.7133 0.9376  -2.106  7.5327  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai   0.9705 0.9413 -0.7636  2.7045  False\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale   0.5133    1.0  -4.306  5.3327  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai   0.9205 0.9671 -0.8136  2.6545  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale   1.6133    1.0  -3.206  6.4327  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai   1.0467 0.8588 -0.6572  2.7506  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock     0.76 0.9967 -0.9439  2.4639  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai   0.1333    1.0 -1.5706  1.8372  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.2133    1.0  -4.606  5.0327  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.3562    1.0 -1.3779  2.0902  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.1133    1.0  -3.706  5.9327  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.601    1.0  -2.335  1.1331  False\n",
            "                         gpt-4o@openai                          original_text  -2.2467 0.0005 -3.9506 -0.5428   True\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra    1.349 0.4151  -0.385  3.0831  False\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai  -1.7429 0.9999  -6.573  3.0872  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale     -2.2    1.0 -8.7992  4.3992  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -1.7929 0.9998  -6.623  3.0372  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -1.1    1.0 -7.6992  5.4992  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -1.6667    1.0  -6.486  3.1527  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  -1.9533 0.9993 -6.7727   2.866  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai    -2.58 0.9638 -7.3993  2.2393  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -2.5 0.9998 -9.0992  4.0992  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -2.3571 0.9883 -7.1872   2.473  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -1.6    1.0 -8.1992  4.9992  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.3143 0.6836 -8.1444  1.5158  False\n",
            "             llama-3-70b-chat@anyscale                          original_text    -4.96 0.0349 -9.7793 -0.1407   True\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra  -1.3643    1.0 -6.1944  3.4658  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale  -0.4571    1.0 -5.2872   4.373  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai    -0.05    1.0 -1.8137  1.7137  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.6429    1.0 -4.1872   5.473  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   0.0762    1.0 -1.6579  1.8102  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.2105    1.0 -1.9445  1.5236  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai  -0.8371 0.9899 -2.5712  0.8969  False\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.7571    1.0 -5.5872   4.073  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.6143 0.9999  -2.378  1.1494  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.1429    1.0 -4.6872   4.973  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.5714 0.1637 -3.3351  0.1923  False\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text  -3.2171    0.0 -4.9512 -1.4831   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.3786    1.0 -1.3851  2.1423  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai   0.4071    1.0  -4.423  5.2372  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale      1.1    1.0 -5.4992  7.6992  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai   0.5333    1.0  -4.286  5.3527  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock   0.2467    1.0 -4.5727   5.066  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai    -0.38    1.0 -5.1993  4.4393  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.3    1.0 -6.8992  6.2992  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -0.1571    1.0 -4.9872   4.673  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale      0.6    1.0 -5.9992  7.1992  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1143    1.0 -5.9444  3.7158  False\n",
            "              llama-3-8b-chat@anyscale                          original_text    -2.76 0.9259 -7.5793  2.0593  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra   0.8357    1.0 -3.9944  5.6658  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.6929    1.0 -4.1372   5.523  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   0.1262    1.0 -1.6079  1.8602  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.1605    1.0 -1.8945  1.5736  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai  -0.7871 0.9957 -2.5212  0.9469  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.7071    1.0 -5.5372   4.123  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5643    1.0  -2.328  1.1994  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.1929    1.0 -4.6372   5.023  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.5214 0.2132 -3.2851  0.2423  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  -3.1671    0.0 -4.9012 -1.4331   True\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.4286    1.0 -1.3351  2.1923  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.5667    1.0  -5.386  4.2527  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock  -0.8533    1.0 -5.6727   3.966  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai    -1.48    1.0 -6.2993  3.3393  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -1.4    1.0 -7.9992  5.1992  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.2571    1.0 -6.0872   3.573  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.5    1.0 -7.0992  6.0992  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.2143 0.9951 -7.0444  2.6158  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text    -3.86  0.353 -8.6793  0.9593  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra  -0.2643    1.0 -5.0944  4.5658  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock  -0.2867    1.0 -1.9906  1.4172  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai  -0.9133 0.9633 -2.6172  0.7906  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.8333    1.0 -5.6527   3.986  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.6905 0.9994 -2.4245  1.0436  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.0667    1.0 -4.7527   4.886  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.6476 0.0888 -3.3817  0.0864  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  -3.2933    0.0 -4.9972 -1.5894   True\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra   0.3024    1.0 -1.4317  2.0364  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai  -0.6267 0.9999 -2.3306  1.0772  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale  -0.5467    1.0  -5.366  4.2727  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra  -0.4038    1.0 -2.1379  1.3302  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale   0.3533    1.0  -4.466  5.1727  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock   -1.361 0.3961  -3.095  0.3731  False\n",
            "             mistral-large@aws-bedrock                          original_text  -3.0067    0.0 -4.7106 -1.3028   True\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra    0.589    1.0  -1.145  2.3231  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale     0.08    1.0 -4.7393  4.8993  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.2229    1.0 -1.5112  1.9569  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale     0.98    1.0 -3.8393  5.7993  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.7343 0.9985 -2.4683  0.9998  False\n",
            "              mistral-small@mistral-ai                          original_text    -2.38 0.0001 -4.0839 -0.6761   True\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra   1.2157 0.6408 -0.5183  2.9498  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   0.1429    1.0 -4.6872   4.973  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale      0.9    1.0 -5.6992  7.4992  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.8143    1.0 -5.6444  4.0158  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text    -2.46 0.9794 -7.2793  2.3593  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   1.1357    1.0 -3.6944  5.9658  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale   0.7571    1.0  -4.073  5.5872  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.9571 0.9578 -2.7208  0.8066  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text  -2.6029    0.0 -4.3369 -0.8688   True\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra   0.9929 0.9377 -0.7708  2.7566  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.7143 0.9999 -6.5444  3.1158  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text    -3.36 0.6521 -8.1793  1.4593  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.2357    1.0 -4.5944  5.0658  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text  -1.6457 0.0899 -3.3798  0.0883  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra     1.95 0.0127  0.1863  3.7137   True\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra   3.5957    0.0  1.8617  5.3298   True\n",
            "--------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}