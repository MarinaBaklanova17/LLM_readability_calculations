{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vaLAbNZRQhq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hCPeFFWStJ3",
        "outputId": "5fec1daf-745f-4826-9d09-678545949e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "control_group = filtered_df[filtered_df['model'] == 'original_text']\n",
        "other_groups = filtered_df[filtered_df['model'] != 'original_text']\n",
        "combined_df = pd.concat([control_group, other_groups])\n",
        "\n",
        "model = ols('Q(\"Flesch-Kincaid Grade Level\") ~ C(model)', data=combined_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "\n",
        "# Tukey's HSD test\n",
        "comp = mc.pairwise_tukeyhsd(combined_df['Flesch-Kincaid Grade Level'], combined_df['model'])\n",
        "tukey_results = pd.DataFrame(data=comp.summary().data[1:], columns=comp.summary().data[0])\n",
        "\n",
        "control_comparisons = tukey_results[tukey_results['group1'] == 'original_text']\n",
        "\n",
        "# Sort by absolute mean difference to find the most similar models\n",
        "control_comparisons_sorted = control_comparisons.sort_values(by='meandiff', key=abs)\n",
        "print(control_comparisons_sorted.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v5oe6v8SziR",
        "outputId": "4d7717e6-a6d8-4a8c-c602-de26524930df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              sum_sq     df         F        PR(>F)\n",
            "C(model)  174.455974   28.0  3.255816  3.008859e-07\n",
            "Residual  524.346667  274.0       NaN           NaN\n",
            "            group1                         group2  meandiff   p-adj   lower  \\\n",
            "405  original_text  qwen-2-72b-instruct@deepinfra    2.5124  0.0006  0.5731   \n",
            "\n",
            "      upper  reject  \n",
            "405  4.4516    True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc\n",
        "\n",
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\",\n",
        "    \"nemotron-4-340b-instruct@deepinfra\",\n",
        "    \"codellama-13b-instruct@together-ai\"\n",
        "]\n",
        "\n",
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['SMOG Index'].describe()\n",
        "\n",
        "\n",
        "print(summary_table)\n",
        "model = ols('Q(\"Flesch-Kincaid Grade Level\") ~ C(model)', data=filtered_df).fit()\n",
        "\n",
        "\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "anova_table.to_excel('anova_table_Flesch-Kincaid Grade Level.xlsx', index=True)\n",
        "\n",
        "# Tukey's HSD test to compare differences between groups\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['Flesch-Kincaid Grade Level'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_Flesch-Kincaid Grade Level.xlsx', index=True) # Call to_excel on the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMrDMonpUU4E",
        "outputId": "b1da6d83-c68d-4c7f-8ede-ecb9c9928467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        count       mean       std   min  \\\n",
            "model                                                                      \n",
            "claude-3-haiku@anthropic                 15.0   9.220000  1.081137   7.4   \n",
            "claude-3-opus@anthropic                  15.0   9.126667  1.181081   6.9   \n",
            "claude-3-sonnet@anthropic                 1.0  11.400000       NaN  11.4   \n",
            "claude-3.5-sonnet@anthropic              15.0   8.846667  1.128758   6.4   \n",
            "gemini-1.5-flash@vertex-ai               15.0   8.733333  1.119098   6.8   \n",
            "gemini-1.5-pro@vertex-ai                 15.0   8.433333  0.718795   7.4   \n",
            "gemma-2-9b-it@fireworks-ai               15.0   8.533333  1.211650   6.2   \n",
            "gemma-2b-it@together-ai                  14.0   9.207143  1.219372   7.1   \n",
            "gemma-7b-it@anyscale                      1.0  10.100000       NaN  10.1   \n",
            "gpt-3.5-turbo@openai                     15.0   9.300000  1.281740   7.7   \n",
            "gpt-4-turbo@openai                       15.0   8.293333  0.786917   6.9   \n",
            "gpt-4@openai                             15.0   8.813333  0.896714   7.6   \n",
            "gpt-4o@openai                            15.0   8.586667  0.709997   7.5   \n",
            "llama-3-70b-chat@anyscale                 1.0  11.300000       NaN  11.3   \n",
            "llama-3-70b-chat@fireworks-ai            14.0   9.557143  1.251900   7.6   \n",
            "llama-3-8b-chat@anyscale                  1.0   9.100000       NaN   9.1   \n",
            "llama-3-8b-chat@fireworks-ai             14.0   9.507143  1.464169   7.0   \n",
            "mistral-7b-instruct-v0.1@anyscale         1.0  10.200000       NaN  10.2   \n",
            "mistral-7b-instruct-v0.3@together-ai     15.0   9.633333  1.217531   7.0   \n",
            "mistral-large@aws-bedrock                15.0   9.346667  0.879827   8.0   \n",
            "mistral-small@mistral-ai                 15.0   8.720000  1.095576   6.8   \n",
            "mixtral-8x22b-instruct-v0.1@anyscale      1.0   8.800000       NaN   8.8   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    14.0   8.942857  0.676773   7.9   \n",
            "mixtral-8x7b-instruct-v0.1@anyscale       1.0   9.700000       NaN   9.7   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   14.0   7.985714  2.523995   0.0   \n",
            "original_text                            15.0   6.340000  2.152009   3.1   \n",
            "qwen-2-72b-instruct@deepinfra            14.0   9.935714  0.826119   8.5   \n",
            "\n",
            "                                           25%    50%     75%   max  \n",
            "model                                                                \n",
            "claude-3-haiku@anthropic                 8.550   9.10  10.200  10.8  \n",
            "claude-3-opus@anthropic                  8.500   9.00   9.800  11.9  \n",
            "claude-3-sonnet@anthropic               11.400  11.40  11.400  11.4  \n",
            "claude-3.5-sonnet@anthropic              8.100   8.80   9.600  10.6  \n",
            "gemini-1.5-flash@vertex-ai               8.050   8.50   9.600  10.9  \n",
            "gemini-1.5-pro@vertex-ai                 7.950   8.40   8.950   9.6  \n",
            "gemma-2-9b-it@fireworks-ai               7.800   8.60   8.900  10.9  \n",
            "gemma-2b-it@together-ai                  8.525   9.75  10.175  10.4  \n",
            "gemma-7b-it@anyscale                    10.100  10.10  10.100  10.1  \n",
            "gpt-3.5-turbo@openai                     8.300   9.20   9.900  12.2  \n",
            "gpt-4-turbo@openai                       7.750   8.20   8.650   9.8  \n",
            "gpt-4@openai                             8.250   8.80   9.100  11.0  \n",
            "gpt-4o@openai                            8.050   8.70   9.000   9.9  \n",
            "llama-3-70b-chat@anyscale               11.300  11.30  11.300  11.3  \n",
            "llama-3-70b-chat@fireworks-ai            8.725   9.40  10.075  11.8  \n",
            "llama-3-8b-chat@anyscale                 9.100   9.10   9.100   9.1  \n",
            "llama-3-8b-chat@fireworks-ai             8.650   9.45  10.100  12.4  \n",
            "mistral-7b-instruct-v0.1@anyscale       10.200  10.20  10.200  10.2  \n",
            "mistral-7b-instruct-v0.3@together-ai     8.900   9.80  10.400  11.4  \n",
            "mistral-large@aws-bedrock                8.600   9.70   9.800  10.9  \n",
            "mistral-small@mistral-ai                 7.800   8.80   9.450  10.8  \n",
            "mixtral-8x22b-instruct-v0.1@anyscale     8.800   8.80   8.800   8.8  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra    8.475   8.95   9.500  10.0  \n",
            "mixtral-8x7b-instruct-v0.1@anyscale      9.700   9.70   9.700   9.7  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock   7.800   8.45   9.175  11.0  \n",
            "original_text                            5.500   7.00   7.350  11.2  \n",
            "qwen-2-72b-instruct@deepinfra            9.550   9.85  10.300  12.1  \n",
            "              sum_sq     df         F        PR(>F)\n",
            "C(model)  170.330875   26.0  3.423356  1.855514e-07\n",
            "Residual  524.346667  274.0       NaN           NaN\n",
            "                                Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic   0.0333    1.0 -1.8538  1.9204  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic     2.54 0.9917 -2.7975  7.8775  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic  -0.6533    1.0 -2.5404  1.2338  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai  -0.5867    1.0 -2.4738  1.3004  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai  -0.8267 0.9975 -2.7138  1.0604  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai  -0.8533 0.9959 -2.7404  1.0338  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai   0.2543    1.0 -1.6662  2.1748  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale     1.44    1.0 -3.8975  6.7775  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai     0.88 0.9937 -1.0071  2.7671  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai  -0.4467    1.0 -2.3338  1.4404  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai    -0.74 0.9996 -2.6271  1.1471  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai  -0.9333 0.9861 -2.8204  0.9538  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale     3.04 0.9298 -2.2975  8.3775  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai   0.9757 0.9805 -0.9448  2.8962  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale     1.04    1.0 -4.2975  6.3775  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai   0.7329 0.9997 -1.1876  2.6534  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale     1.04    1.0 -4.2975  6.3775  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5667    1.0 -1.3204  2.4538  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock   0.2533    1.0 -1.6338  2.1404  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai  -0.4733    1.0 -2.3604  1.4138  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     0.54    1.0 -4.7975  5.8775  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5243    1.0 -2.4448  1.3962  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     0.84    1.0 -4.4975  6.1775  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4243    1.0 -2.3448  1.4962  False\n",
            "              claude-3-haiku@anthropic                          original_text  -1.0867 0.9217 -2.9738  0.8004  False\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra   1.4257 0.5182 -0.4948  3.3462  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic   2.5067 0.9931 -2.8308  7.8442  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic  -0.6867 0.9999 -2.5738  1.2004  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai    -0.62    1.0 -2.5071  1.2671  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai    -0.86 0.9955 -2.7471  1.0271  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai  -0.8867  0.993 -2.7738  1.0004  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai    0.221    1.0 -1.6995  2.1415  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale   1.4067    1.0 -3.9308  6.7442  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai   0.8467 0.9964 -1.0404  2.7338  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai    -0.48    1.0 -2.3671  1.4071  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai  -0.7733 0.9991 -2.6604  1.1138  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai  -0.9667 0.9784 -2.8538  0.9204  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale   3.0067 0.9373 -2.3308  8.3442  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai   0.9424 0.9875 -0.9781  2.8629  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale   1.0067    1.0 -4.3308  6.3442  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai   0.6995 0.9999  -1.221    2.62  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale   1.0067    1.0 -4.3308  6.3442  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5333    1.0 -1.3538  2.4204  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock     0.22    1.0 -1.6671  2.1071  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai  -0.5067    1.0 -2.3938  1.3804  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   0.5067    1.0 -4.8308  5.8442  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5576    1.0 -2.4781  1.3629  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   0.8067    1.0 -4.5308  6.1442  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4576    1.0 -2.3781  1.4629  False\n",
            "               claude-3-opus@anthropic                          original_text    -1.12 0.8957 -3.0071  0.7671  False\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra   1.3924 0.5699 -0.5281  3.3129  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  -3.1933 0.8878 -8.5308  2.1442  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -3.1267 0.9077 -8.4642  2.2108  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -3.3667 0.8247 -8.7042  1.9708  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  -3.3933 0.8135 -8.7308  1.9442  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai  -2.2857 0.9983 -7.6351  3.0637  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale     -1.1    1.0 -8.4087  6.2087  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai    -1.66    1.0 -6.9975  3.6775  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  -2.9867 0.9414 -8.3242  2.3508  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai    -3.28 0.8583 -8.6175  2.0575  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  -3.4733  0.778 -8.8108  1.8642  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale      0.5    1.0 -6.8087  7.8087  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai  -1.5643    1.0 -6.9137  3.7851  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale     -1.5    1.0 -8.8087  5.8087  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai  -1.8071    1.0 -7.1566  3.5423  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale     -1.5    1.0 -8.8087  5.8087  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai  -1.9733 0.9998 -7.3108  3.3642  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock  -2.2867 0.9982 -7.6242  3.0508  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai  -3.0133 0.9358 -8.3508  2.3242  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -3.0643 0.9257 -8.4137  2.2851  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     -1.7    1.0 -9.0087  5.6087  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.9643 0.9471 -8.3137  2.3851  False\n",
            "             claude-3-sonnet@anthropic                          original_text  -3.6267 0.7024 -8.9642  1.7108  False\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra  -1.1143    1.0 -6.4637  4.2351  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai   0.0667    1.0 -1.8204  1.9538  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -0.1733    1.0 -2.0604  1.7138  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai     -0.2    1.0 -2.0871  1.6871  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai   0.9076 0.9924 -1.0129  2.8281  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale   2.0933 0.9996 -3.2442  7.4308  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai   1.5333 0.3236 -0.3538  3.4204  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai   0.2067    1.0 -1.6804  2.0938  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai  -0.0867    1.0 -1.9738  1.8004  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai    -0.28    1.0 -2.1671  1.6071  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale   3.6933 0.6672 -1.6442  9.0308  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai    1.629 0.2419 -0.2915  3.5495  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   1.3862 0.5795 -0.5343  3.3067  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai     1.22 0.7884 -0.6671  3.1071  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock   0.9067 0.9905 -0.9804  2.7938  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai     0.18    1.0 -1.7071  2.0671  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   1.1933    1.0 -4.1442  6.5308  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra    0.129    1.0 -1.7915  2.0495  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   1.4933    1.0 -3.8442  6.8308  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock    0.229    1.0 -1.6915  2.1495  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text  -0.4333    1.0 -2.3204  1.4538  False\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra    2.079 0.0174  0.1585  3.9995   True\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai    -0.24    1.0 -2.1271  1.6471  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai  -0.2667    1.0 -2.1538  1.6204  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai    0.841 0.9975 -1.0795  2.7615  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale   2.0267 0.9998 -3.3108  7.3642  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai   1.4667 0.4172 -0.4204  3.3538  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai     0.14    1.0 -1.7471  2.0271  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai  -0.1533    1.0 -2.0404  1.7338  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai  -0.3467    1.0 -2.2338  1.5404  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale   3.6267 0.7024 -1.7108  8.9642  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai   1.5624 0.3211 -0.3581  3.4829  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale   1.6267    1.0 -3.7108  6.9642  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai   1.3195 0.6811  -0.601    3.24  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.6267    1.0 -3.7108  6.9642  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai   1.1533 0.8648 -0.7338  3.0404  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock     0.84 0.9968 -1.0471  2.7271  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai   0.1133    1.0 -1.7738  2.0004  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.1267    1.0 -4.2108  6.4642  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.0624    1.0 -1.8581  1.9829  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.4267    1.0 -3.9108  6.7642  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.1624    1.0 -1.7581  2.0829  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text     -0.5    1.0 -2.3871  1.3871  False\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra   2.0124 0.0275  0.0919  3.9329   True\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai  -0.0267    1.0 -1.9138  1.8604  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai    1.081 0.9378 -0.8395  3.0015  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale   2.2667 0.9984 -3.0708  7.6042  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai   1.7067 0.1435 -0.1804  3.5938  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai     0.38    1.0 -1.5071  2.2671  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai   0.0867    1.0 -1.8004  1.9738  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai  -0.1067    1.0 -1.9938  1.7804  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale   3.8667 0.5717 -1.4708  9.2042  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai   1.8024 0.1008 -0.1181  3.7229  False\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale   1.8667 0.9999 -3.4708  7.2042  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai   1.5595 0.3248  -0.361    3.48  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.8667 0.9999 -3.4708  7.2042  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai   1.3933 0.5301 -0.4938  3.2804  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock     1.08 0.9264 -0.8071  2.9671  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai   0.3533    1.0 -1.5338  2.2404  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.3667    1.0 -3.9708  6.7042  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.3024    1.0 -1.6181  2.2229  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.6667    1.0 -3.6708  7.0042  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.4024    1.0 -1.5181  2.3229  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text    -0.26    1.0 -2.1471  1.6271  False\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra   2.2524 0.0048  0.3319  4.1729   True\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai   1.1076 0.9205 -0.8129  3.0281  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale   2.2933 0.9981 -3.0442  7.6308  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai   1.7333 0.1244 -0.1538  3.6204  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai   0.4067    1.0 -1.4804  2.2938  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai   0.1133    1.0 -1.7738  2.0004  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai    -0.08    1.0 -1.9671  1.8071  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale   3.8933 0.5567 -1.4442  9.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai    1.829 0.0866 -0.0915  3.7495  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale   1.8933 0.9999 -3.4442  7.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai   1.5862 0.2913 -0.3343  3.5067  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   1.8933 0.9999 -3.4442  7.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai     1.42 0.4883 -0.4671  3.3071  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock   1.1067 0.9067 -0.7804  2.9938  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai     0.38    1.0 -1.5071  2.2671  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.3933    1.0 -3.9442  6.7308  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra    0.329    1.0 -1.5915  2.2495  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.429    1.0 -1.4915  2.3495  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text  -0.2333    1.0 -2.1204  1.6538  False\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra    2.279 0.0039  0.3585  4.1995   True\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale   1.1857    1.0 -4.1637  6.5351  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai   0.6257    1.0 -1.2948  2.5462  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai   -0.701 0.9999 -2.6215  1.2195  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai  -0.9943 0.9755 -2.9148  0.9262  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai  -1.1876 0.8507 -3.1081  0.7329  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale   2.7857 0.9737 -2.5637  8.1351  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai   0.7214 0.9998 -1.2319  2.6748  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale   0.7857    1.0 -4.5637  6.1351  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai   0.4786    1.0 -1.4748  2.4319  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale   0.7857    1.0 -4.5637  6.1351  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai   0.3124    1.0 -1.6081  2.2329  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock   -0.001    1.0 -1.9215  1.9195  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai  -0.7276 0.9998 -2.6481  1.1929  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.2857    1.0 -5.0637  5.6351  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.7786 0.9994 -2.7319  1.1748  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.5857    1.0 -4.7637  5.9351  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.6786 0.9999 -2.6319  1.2748  False\n",
            "               gemma-2b-it@together-ai                          original_text   -1.341 0.6491 -3.2615  0.5795  False\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra   1.1714 0.8854 -0.7819  3.1248  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai    -0.56    1.0 -5.8975  4.7775  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  -1.8867 0.9999 -7.2242  3.4508  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai    -2.18 0.9992 -7.5175  3.1575  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  -2.3733 0.9968 -7.7108  2.9642  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale      1.6    1.0 -5.7087  8.9087  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai  -0.4643    1.0 -5.8137  4.8851  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale     -0.4    1.0 -7.7087  6.9087  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai  -0.7071    1.0 -6.0566  4.6423  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale     -0.4    1.0 -7.7087  6.9087  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.8733    1.0 -6.2108  4.4642  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  -1.1867    1.0 -6.5242  4.1508  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai  -1.9133 0.9999 -7.2508  3.4242  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.9    1.0 -8.2087  6.4087  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.9643 0.9999 -7.3137  3.3851  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.6    1.0 -7.9087  6.7087  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.8643 0.9999 -7.2137  3.4851  False\n",
            "                  gemma-7b-it@anyscale                          original_text  -2.5267 0.9922 -7.8642  2.8108  False\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra  -0.0143    1.0 -5.3637  5.3351  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai  -1.3267 0.6351 -3.2138  0.5604  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai    -1.62 0.2212 -3.5071  0.2671  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai  -1.8133 0.0788 -3.7004  0.0738  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale     2.16 0.9993 -3.1775  7.4975  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai   0.0957    1.0 -1.8248  2.0162  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale     0.16    1.0 -5.1775  5.4975  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai  -0.1471    1.0 -2.0676  1.7734  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale     0.16    1.0 -5.1775  5.4975  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai  -0.3133    1.0 -2.2004  1.5738  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock  -0.6267    1.0 -2.5138  1.2604  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai  -1.3533 0.5933 -3.2404  0.5338  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale    -0.34    1.0 -5.6775  4.9975  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.4043 0.5514 -3.3248  0.5162  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale    -0.04    1.0 -5.3775  5.2975  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3043 0.7034 -3.2248  0.6162  False\n",
            "                  gpt-3.5-turbo@openai                          original_text  -1.9667 0.0296 -3.8538 -0.0796   True\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra   0.5457    1.0 -1.3748  2.4662  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai  -0.2933    1.0 -2.1804  1.5938  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai  -0.4867    1.0 -2.3738  1.4004  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale   3.4867 0.7718 -1.8508  8.8242  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai   1.4224 0.5233 -0.4981  3.3429  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale   1.4867    1.0 -3.8508  6.8242  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai   1.1795  0.859  -0.741     3.1  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale   1.4867    1.0 -3.8508  6.8242  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai   1.0133 0.9625 -0.8738  2.9004  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock      0.7 0.9998 -1.1871  2.5871  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai  -0.0267    1.0 -1.9138  1.8604  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.9867    1.0 -4.3508  6.3242  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.0776    1.0 -1.9981  1.8429  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.2867    1.0 -4.0508  6.6242  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.0224    1.0 -1.8981  1.9429  False\n",
            "                    gpt-4-turbo@openai                          original_text    -0.64    1.0 -2.5271  1.2471  False\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   1.8724 0.0672 -0.0481  3.7929  False\n",
            "                          gpt-4@openai                          gpt-4o@openai  -0.1933    1.0 -2.0804  1.6938  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale     3.78 0.6199 -1.5575  9.1175  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai   1.7157   0.16 -0.2048  3.6362  False\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale     1.78    1.0 -3.5575  7.1175  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai   1.4729 0.4464 -0.4476  3.3934  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale     1.78    1.0 -3.5575  7.1175  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai   1.3067 0.6658 -0.5804  3.1938  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock   0.9933 0.9702 -0.8938  2.8804  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai   0.2667    1.0 -1.6204  2.1538  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale     1.28    1.0 -4.0575  6.6175  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.2157    1.0 -1.7048  2.1362  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale     1.58    1.0 -3.7575  6.9175  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.3157    1.0 -1.6048  2.2362  False\n",
            "                          gpt-4@openai                          original_text  -0.3467    1.0 -2.2338  1.5404  False\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra   2.1657 0.0093  0.2452  4.0862   True\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale   3.9733 0.5121 -1.3642  9.3108  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai    1.909 0.0537 -0.0115  3.8295  False\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale   1.9733 0.9998 -3.3642  7.3108  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai   1.6662 0.2039 -0.2543  3.5867  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale   1.9733 0.9998 -3.3642  7.3108  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai      1.5  0.369 -0.3871  3.3871  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock   1.1867 0.8289 -0.7004  3.0738  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai     0.46    1.0 -1.4271  2.3471  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale   1.4733    1.0 -3.8642  6.8108  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra    0.409    1.0 -1.5115  2.3295  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.7733    1.0 -3.5642  7.1108  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.509    1.0 -1.4115  2.4295  False\n",
            "                         gpt-4o@openai                          original_text  -0.1533    1.0 -2.0404  1.7338  False\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra    2.359  0.002  0.4385  4.2795   True\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai  -2.0643 0.9997 -7.4137  3.2851  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -2.3071  0.998 -7.6566  3.0423  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -2.4733 0.9942 -7.8108  2.8642  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  -2.7867 0.9729 -8.1242  2.5508  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai  -3.5133 0.7592 -8.8508  1.8242  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -2.5    1.0 -9.8087  4.8087  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -3.5643 0.7382 -8.9137  1.7851  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -2.2    1.0 -9.5087  5.1087  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.4643 0.7857 -8.8137  1.8851  False\n",
            "             llama-3-70b-chat@anyscale                          original_text  -4.1267 0.4286 -9.4642  1.2108  False\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra  -1.6143    1.0 -6.9637  3.7351  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale   0.0643    1.0 -5.2851  5.4137  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai  -0.2429    1.0 -2.1962  1.7105  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.0643    1.0 -5.2851  5.4137  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   -0.409    1.0 -2.3295  1.5115  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.7224 0.9998 -2.6429  1.1981  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai   -1.449 0.4823 -3.3695  0.4715  False\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.4357    1.0 -5.7851  4.9137  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra     -1.5 0.4435 -3.4533  0.4533  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.1357    1.0 -5.4851  5.2137  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock     -1.4 0.5946 -3.3533  0.5533  False\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text  -2.0624 0.0195 -3.9829 -0.1419   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra     0.45    1.0 -1.5033  2.4033  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -0.3071    1.0 -5.6566  5.0423  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale      0.0    1.0 -7.3087  7.3087  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.4733    1.0 -5.8108  4.8642  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock  -0.7867    1.0 -6.1242  4.5508  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai  -1.5133    1.0 -6.8508  3.8242  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.5    1.0 -7.8087  6.8087  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.5643    1.0 -6.9137  3.7851  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.2    1.0 -7.5087  7.1087  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.4643    1.0 -6.8137  3.8851  False\n",
            "              llama-3-8b-chat@anyscale                          original_text  -2.1267 0.9994 -7.4642  3.2108  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra   0.3857    1.0 -4.9637  5.7351  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.3071    1.0 -5.0423  5.6566  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -0.1662    1.0 -2.0867  1.7543  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.4795    1.0    -2.4   1.441  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai  -1.2062 0.8305 -3.1267  0.7143  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.1929    1.0 -5.5423  5.1566  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.2571 0.7953 -3.2105  0.6962  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.1071    1.0 -5.2423  5.4566  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1571 0.8975 -3.1105  0.7962  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  -1.8195 0.0915   -3.74   0.101  False\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.6929 0.9999 -1.2605  2.6462  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.4733    1.0 -5.8108  4.8642  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock  -0.7867    1.0 -6.1242  4.5508  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai  -1.5133    1.0 -6.8508  3.8242  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.5    1.0 -7.8087  6.8087  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.5643    1.0 -6.9137  3.7851  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.2    1.0 -7.5087  7.1087  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.4643    1.0 -6.8137  3.8851  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text  -2.1267 0.9994 -7.4642  3.2108  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.3857    1.0 -4.9637  5.7351  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock  -0.3133    1.0 -2.2004  1.5738  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai    -1.04 0.9501 -2.9271  0.8471  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.0267    1.0 -5.3642  5.3108  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -1.091 0.9317 -3.0115  0.8295  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.2733    1.0 -5.0642  5.6108  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.991 0.9765 -2.9115  0.9295  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  -1.6533 0.1885 -3.5404  0.2338  False\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra    0.859 0.9965 -1.0615  2.7795  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai  -0.7267 0.9997 -2.6138  1.1604  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale   0.2867    1.0 -5.0508  5.6242  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra  -0.7776 0.9993 -2.6981  1.1429  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale   0.5867    1.0 -4.7508  5.9242  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.6776 0.9999 -2.5981  1.2429  False\n",
            "             mistral-large@aws-bedrock                          original_text    -1.34 0.6143 -3.2271  0.5471  False\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra   1.1724 0.8661 -0.7481  3.0929  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.0133    1.0 -4.3242  6.3508  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.051    1.0 -1.9715  1.8695  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.3133    1.0 -4.0242  6.6508  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.049    1.0 -1.8715  1.9695  False\n",
            "              mistral-small@mistral-ai                          original_text  -0.6133    1.0 -2.5004  1.2738  False\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra    1.899 0.0571 -0.0215  3.8195  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.0643    1.0 -6.4137  4.2851  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale      0.3    1.0 -7.0087  7.6087  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.9643    1.0 -6.3137  4.3851  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text  -1.6267    1.0 -6.9642  3.7108  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.8857    1.0 -4.4637  6.2351  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale   1.3643    1.0 -3.9851  6.7137  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock      0.1    1.0 -1.8533  2.0533  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text  -0.5624    1.0 -2.4829  1.3581  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra     1.95  0.051 -0.0033  3.9033  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2643    1.0 -6.6137  4.0851  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text  -1.9267 0.9999 -7.2642  3.4108  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.5857    1.0 -4.7637  5.9351  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text  -0.6624    1.0 -2.5829  1.2581  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra     1.85 0.0918 -0.1033  3.8033  False\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra   2.5124 0.0005  0.5919  4.4329   True\n",
            "--------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_table = filtered_df.groupby('model')['Flesch-Kincaid Grade Level'].describe()\n",
        "anova_df = pd.DataFrame(anova_table)\n",
        "\n",
        "output_file_path = 'summary_and_anova_output_Flesch-Kincaid Grade Level.xlsx'\n",
        "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
        "    summary_table.to_excel(writer, sheet_name='Summary Statistics')\n",
        "    anova_df.to_excel(writer, sheet_name='ANOVA Table')\n",
        "\n",
        "print(f\"Data has been saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnKjUKzNBAIR",
        "outputId": "6f33419e-c652-46f2-fa05-01d6c70e9b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to summary_and_anova_output_Flesch-Kincaid Grade Level.xlsx\n"
          ]
        }
      ]
    }
  ]
}