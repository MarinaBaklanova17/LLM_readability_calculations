{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZFI_5VZF8DIt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as mc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel('overalldata.xlsx', sheet_name='Sheet1')\n",
        "exclude_models = [\n",
        "    \"codellama-70b-instruct@anyscale\",\n",
        "    \"codellama-7b-instruct@together-ai\",\n",
        "    \"command-r-plus@aws-bedrock\",\n",
        "    \"deepseek-coder-33b-instruct@together-ai\",\n",
        "    \"phi-3-medium-4k-instruct@deepinfra\",\n",
        "    \"nemotron-4-340b-instruct@deepinfra\",\n",
        "    \"codellama-13b-instruct@together-ai\"\n",
        "]"
      ],
      "metadata": {
        "id": "pvAHpifA-XPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tukey's HSD test to compare differences for Automated Readability Index"
      ],
      "metadata": {
        "id": "Y-VUm9CCCsji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['Automated Readability Index'].describe()\n",
        "\n",
        "# Tukey's HSD test to compare differences Automated Readability Index\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['Automated Readability Index'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_Automated Readability Index.xlsx', index=True)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDLdHfY6-e9E",
        "outputId": "fe5f1bdd-d28b-4344-9925-4eb5dcfab3d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "=====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower    upper  reject\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic  -0.1133    1.0  -2.4422  2.2156  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic     3.58 0.9571  -3.0071 10.1671  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic  -0.6667    1.0  -2.9956  1.6622  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai  -0.3667    1.0  -2.6956  1.9622  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai  -0.8133 0.9999  -3.1422  1.5156  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai  -0.1133    1.0  -2.4422  2.2156  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai   0.3157    1.0  -2.0544  2.6858  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale     1.08    1.0  -5.5071  7.6671  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai   0.6733    1.0  -1.6556  3.0022  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai  -0.1667    1.0  -2.4956  2.1622  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai  -1.1867 0.9798  -3.5156  1.1422  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai  -1.0667 0.9951  -3.3956  1.2622  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale     3.38  0.978  -3.2071  9.9671  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai     1.58 0.7373  -0.7901  3.9501  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale     0.58    1.0  -6.0071  7.1671  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai   0.9657 0.9992  -1.4044  3.3358  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale    -0.52    1.0  -7.1071  6.0671  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai   0.7933    1.0  -1.5356  3.1222  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock   0.1867    1.0  -2.1422  2.5156  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai  -0.8267 0.9999  -3.1556  1.5022  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     0.68    1.0  -5.9071  7.2671  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.6486    1.0  -3.0187  1.7215  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale    -0.42    1.0  -7.0071  6.1671  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.5986    1.0  -2.9687  1.7715  False\n",
            "              claude-3-haiku@anthropic                          original_text     -0.8    1.0  -3.1289  1.5289  False\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra   1.7371 0.5463   -0.633  4.1073  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic   3.6933 0.9402  -2.8938 10.2804  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic  -0.5533    1.0  -2.8822  1.7756  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai  -0.2533    1.0  -2.5822  2.0756  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai     -0.7    1.0  -3.0289  1.6289  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai      0.0    1.0  -2.3289  2.3289  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai    0.429    1.0  -1.9411  2.7992  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale   1.1933    1.0  -5.3938  7.7804  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai   0.7867    1.0  -1.5422  3.1156  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai  -0.0533    1.0  -2.3822  2.2756  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai  -1.0733 0.9947  -3.4022  1.2556  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai  -0.9533 0.9991  -3.2822  1.3756  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale   3.4933 0.9675  -3.0938 10.0804  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai   1.6933 0.6014  -0.6768  4.0634  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale   0.6933    1.0  -5.8938  7.2804  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai    1.079 0.9955  -1.2911  3.4492  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale  -0.4067    1.0  -6.9938  6.1804  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   0.9067 0.9996  -1.4222  3.2356  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock      0.3    1.0  -2.0289  2.6289  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai  -0.7133    1.0  -3.0422  1.6156  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   0.7933    1.0  -5.7938  7.3804  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5352    1.0  -2.9054  1.8349  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -0.3067    1.0  -6.8938  6.2804  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4852    1.0  -2.8554  1.8849  False\n",
            "               claude-3-opus@anthropic                          original_text  -0.6867    1.0  -3.0156  1.6422  False\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra   1.8505 0.4073  -0.5196  4.2206  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  -4.2467 0.7927 -10.8338  2.3404  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -3.9467 0.8864 -10.5338  2.6404  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -4.3933 0.7364 -10.9804  2.1938  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  -3.6933 0.9402 -10.2804  2.8938  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai  -3.2643 0.9862  -9.8661  3.3375  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale     -2.5    1.0 -11.5198  6.5198  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai  -2.9067 0.9972  -9.4938  3.6804  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  -3.7467 0.9308 -10.3338  2.8404  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai  -4.7667  0.574 -11.3538  1.8204  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  -4.6467 0.6281 -11.2338  1.9404  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale     -0.2    1.0  -9.2198  8.8198  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai     -2.0    1.0  -8.6018  4.6018  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale     -3.0    1.0 -12.0198  6.0198  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai  -2.6143 0.9995  -9.2161  3.9875  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale     -4.1 0.9956 -13.1198  4.9198  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai  -2.7867 0.9985  -9.3738  3.8004  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock  -3.3933 0.9769  -9.9804  3.1938  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai  -4.4067  0.731 -10.9938  2.1804  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     -2.9    1.0 -11.9198  6.1198  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -4.2286 0.8026 -10.8304  2.3732  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     -4.0  0.997 -13.0198  5.0198  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -4.1786 0.8198 -10.7804  2.4232  False\n",
            "             claude-3-sonnet@anthropic                          original_text    -4.38 0.7418 -10.9671  2.2071  False\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra  -1.8429    1.0  -8.4446  4.7589  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai      0.3    1.0  -2.0289  2.6289  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -0.1467    1.0  -2.4756  2.1822  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai   0.5533    1.0  -1.7756  2.8822  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai   0.9824 0.9989  -1.3877  3.3525  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale   1.7467    1.0  -4.8404  8.3338  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai     1.34 0.9223  -0.9889  3.6689  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai      0.5    1.0  -1.8289  2.8289  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai    -0.52    1.0  -2.8489  1.8089  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai     -0.4    1.0  -2.7289  1.9289  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale   4.0467 0.8587  -2.5404 10.6338  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai   2.2467  0.091  -0.1234  4.6168  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale   1.2467    1.0  -5.3404  7.8338  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   1.6324 0.6764  -0.7377  4.0025  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale   0.1467    1.0  -6.4404  6.7338  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai     1.46  0.833  -0.8689  3.7889  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock   0.8533 0.9999  -1.4756  3.1822  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai    -0.16    1.0  -2.4889  2.1689  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   1.3467    1.0  -5.2404  7.9338  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra   0.0181    1.0   -2.352  2.3882  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   0.2467    1.0  -6.3404  6.8338  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   0.0681    1.0   -2.302  2.4382  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text  -0.1333    1.0  -2.4622  2.1956  False\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra   2.4038 0.0421   0.0337  4.7739   True\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai  -0.4467    1.0  -2.7756  1.8822  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai   0.2533    1.0  -2.0756  2.5822  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai   0.6824    1.0  -1.6877  3.0525  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale   1.4467    1.0  -5.1404  8.0338  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai     1.04 0.9966  -1.2889  3.3689  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai      0.2    1.0  -2.1289  2.5289  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai    -0.82 0.9999  -3.1489  1.5089  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai     -0.7    1.0  -3.0289  1.6289  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale   3.7467 0.9308  -2.8404 10.3338  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai   1.9467 0.3021  -0.4234  4.3168  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale   0.9467    1.0  -5.6404  7.5338  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai   1.3324 0.9386  -1.0377  3.7025  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale  -0.1533    1.0  -6.7404  6.4338  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai     1.16 0.9848  -1.1689  3.4889  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock   0.5533    1.0  -1.7756  2.8822  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai    -0.46    1.0  -2.7889  1.8689  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.0467    1.0  -5.5404  7.6338  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.2819    1.0   -2.652  2.0882  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.0533    1.0  -6.6404  6.5338  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.2319    1.0   -2.602  2.1382  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text  -0.4333    1.0  -2.7622  1.8956  False\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra   2.1038  0.169  -0.2663  4.4739  False\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai      0.7    1.0  -1.6289  3.0289  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai    1.129 0.9916  -1.2411  3.4992  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale   1.8933    1.0  -4.6938  8.4804  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai   1.4867 0.8076  -0.8422  3.8156  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai   0.6467    1.0  -1.6822  2.9756  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai  -0.3733    1.0  -2.7022  1.9556  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai  -0.2533    1.0  -2.5822  2.0756  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale   4.1933 0.8116  -2.3938 10.7804  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai   2.3933 0.0444   0.0232  4.7634   True\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale   1.3933    1.0  -5.1938  7.9804  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai    1.779 0.4938  -0.5911  4.1492  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale   0.2933    1.0  -6.2938  6.8804  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai   1.6067 0.6731  -0.7222  3.9356  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock      1.0 0.9981  -1.3289  3.3289  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai  -0.0133    1.0  -2.3422  2.3156  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.4933    1.0  -5.0938  8.0804  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.1648    1.0  -2.2054  2.5349  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.3933    1.0  -6.1938  6.9804  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.2148    1.0  -2.1554  2.5849  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text   0.0133    1.0  -2.3156  2.3422  False\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra   2.5505  0.019   0.1804  4.9206   True\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai    0.429    1.0  -1.9411  2.7992  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale   1.1933    1.0  -5.3938  7.7804  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai   0.7867    1.0  -1.5422  3.1156  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai  -0.0533    1.0  -2.3822  2.2756  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai  -1.0733 0.9947  -3.4022  1.2556  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai  -0.9533 0.9991  -3.2822  1.3756  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale   3.4933 0.9675  -3.0938 10.0804  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai   1.6933 0.6014  -0.6768  4.0634  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale   0.6933    1.0  -5.8938  7.2804  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai    1.079 0.9955  -1.2911  3.4492  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -0.4067    1.0  -6.9938  6.1804  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   0.9067 0.9996  -1.4222  3.2356  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock      0.3    1.0  -2.0289  2.6289  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai  -0.7133    1.0  -3.0422  1.6156  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.7933    1.0  -5.7938  7.3804  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5352    1.0  -2.9054  1.8349  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.3067    1.0  -6.8938  6.2804  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4852    1.0  -2.8554  1.8849  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text  -0.6867    1.0  -3.0156  1.6422  False\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra   1.8505 0.4073  -0.5196  4.2206  False\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale   0.7643    1.0  -5.8375  7.3661  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai   0.3576    1.0  -2.0125  2.7277  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai  -0.4824    1.0  -2.8525  1.8877  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai  -1.5024 0.8177  -3.8725  0.8677  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai  -1.3824 0.9114  -3.7525  0.9877  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale   3.0643 0.9941  -3.5375  9.6661  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai   1.2643 0.9714  -1.1463  3.6749  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale   0.2643    1.0  -6.3375  6.8661  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai     0.65    1.0  -1.7606  3.0606  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale  -0.8357    1.0  -7.4375  5.7661  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai   0.4776    1.0  -1.8925  2.8477  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock   -0.129    1.0  -2.4992  2.2411  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai  -1.1424 0.9901  -3.5125  1.2277  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.3643    1.0  -6.2375  6.9661  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.9643 0.9994  -3.3749  1.4463  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.7357    1.0  -7.3375  5.8661  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.9143 0.9998  -3.3249  1.4963  False\n",
            "               gemma-2b-it@together-ai                          original_text  -1.1157 0.9928  -3.4858  1.2544  False\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra   1.4214 0.9018  -0.9892  3.8321  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai  -0.4067    1.0  -6.9938  6.1804  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  -1.2467    1.0  -7.8338  5.3404  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai  -2.2667    1.0  -8.8538  4.3204  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  -2.1467    1.0  -8.7338  4.4404  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale      2.3    1.0  -6.7198 11.3198  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai      0.5    1.0  -6.1018  7.1018  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale     -0.5    1.0  -9.5198  8.5198  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai  -0.1143    1.0  -6.7161  6.4875  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale     -1.6    1.0 -10.6198  7.4198  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.2867    1.0  -6.8738  6.3004  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  -0.8933    1.0  -7.4804  5.6938  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai  -1.9067    1.0  -8.4938  4.6804  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.4    1.0  -9.4198  8.6198  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.7286    1.0  -8.3304  4.8732  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -1.5    1.0 -10.5198  7.5198  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.6786    1.0  -8.2804  4.9232  False\n",
            "                  gemma-7b-it@anyscale                          original_text    -1.88    1.0  -8.4671  4.7071  False\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra   0.6571    1.0  -5.9446  7.2589  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai    -0.84 0.9999  -3.1689  1.4889  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai    -1.86  0.359  -4.1889  0.4689  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai    -1.74 0.5041  -4.0689  0.5889  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale   2.7067 0.9991  -3.8804  9.2938  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai   0.9067 0.9997  -1.4634  3.2768  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale  -0.0933    1.0  -6.6804  6.4938  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai   0.2924    1.0  -2.0777  2.6625  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale  -1.1933    1.0  -7.7804  5.3938  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai     0.12    1.0  -2.2089  2.4489  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock  -0.4867    1.0  -2.8156  1.8422  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai     -1.5 0.7942  -3.8289  0.8289  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.0067    1.0  -6.5804  6.5938  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.3219 0.9434   -3.692  1.0482  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale  -1.0933    1.0  -7.6804  5.4938  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2719 0.9628   -3.642  1.0982  False\n",
            "                  gpt-3.5-turbo@openai                          original_text  -1.4733 0.8205  -3.8022  0.8556  False\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra   1.0638 0.9964  -1.3063  3.4339  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai    -1.02 0.9975  -3.3489  1.3089  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai     -0.9 0.9997  -3.2289  1.4289  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale   3.5467 0.9614  -3.0404 10.1338  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai   1.7467 0.5343  -0.6234  4.1168  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale   0.7467    1.0  -5.8404  7.3338  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai   1.1324 0.9912  -1.2377  3.5025  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale  -0.3533    1.0  -6.9404  6.2338  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai     0.96  0.999  -1.3689  3.2889  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock   0.3533    1.0  -1.9756  2.6822  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai    -0.66    1.0  -2.9889  1.6689  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.8467    1.0  -5.7404  7.4338  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.4819    1.0   -2.852  1.8882  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale  -0.2533    1.0  -6.8404  6.3338  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4319    1.0   -2.802  1.9382  False\n",
            "                    gpt-4-turbo@openai                          original_text  -0.6333    1.0  -2.9622  1.6956  False\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   1.9038  0.347  -0.4663  4.2739  False\n",
            "                          gpt-4@openai                          gpt-4o@openai     0.12    1.0  -2.2089  2.4489  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale   4.5667 0.6634  -2.0204 11.1538  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai   2.7667 0.0052   0.3966  5.1368   True\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale   1.7667    1.0  -4.8204  8.3538  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai   2.1524 0.1382  -0.2177  4.5225  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale   0.6667    1.0  -5.9204  7.2538  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai     1.98 0.2379  -0.3489  4.3089  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock   1.3733 0.9018  -0.9556  3.7022  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai     0.36    1.0  -1.9689  2.6889  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale   1.8667    1.0  -4.7204  8.4538  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.5381    1.0   -1.832  2.9082  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale   0.7667    1.0  -5.8204  7.3538  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.5881    1.0   -1.782  2.9582  False\n",
            "                          gpt-4@openai                          original_text   0.3867    1.0  -1.9422  2.7156  False\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra   2.9238 0.0019   0.5537  5.2939   True\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale   4.4467 0.7146  -2.1404 11.0338  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai   2.6467 0.0108   0.2766  5.0168   True\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale   1.6467    1.0  -4.9404  8.2338  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai   2.0324 0.2231  -0.3377  4.4025  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale   0.5467    1.0  -6.0404  7.1338  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai     1.86  0.359  -0.4689  4.1889  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock   1.2533 0.9616  -1.0756  3.5822  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai     0.24    1.0  -2.0889  2.5689  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale   1.7467    1.0  -4.8404  8.3338  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.4181    1.0   -1.952  2.7882  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale   0.6467    1.0  -5.9404  7.2338  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.4681    1.0   -1.902  2.8382  False\n",
            "                         gpt-4o@openai                          original_text   0.2667    1.0  -2.0622  2.5956  False\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra   2.8038 0.0041   0.4337  5.1739   True\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai     -1.8    1.0  -8.4018  4.8018  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale     -2.8    1.0 -11.8198  6.2198  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -2.4143 0.9999  -9.0161  4.1875  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -3.9 0.9979 -12.9198  5.1198  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -2.5867 0.9996  -9.1738  4.0004  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  -3.1933 0.9893  -9.7804  3.3938  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai  -4.2067  0.807 -10.7938  2.3804  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -2.7    1.0 -11.7198  6.3198  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -4.0286 0.8665 -10.6304  2.5732  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -3.8 0.9986 -12.8198  5.2198  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.9786 0.8803 -10.5804  2.6232  False\n",
            "             llama-3-70b-chat@anyscale                          original_text    -4.18 0.8162 -10.7671  2.4071  False\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra  -1.6429    1.0  -8.2446  4.9589  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale     -1.0    1.0  -7.6018  5.6018  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai  -0.6143    1.0  -3.0249  1.7963  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale     -2.1    1.0  -8.7018  4.5018  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -0.7867    1.0  -3.1568  1.5834  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock  -1.3933 0.9046  -3.7634  0.9768  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai  -2.4067 0.0414  -4.7768 -0.0366   True\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale     -0.9    1.0  -7.5018  5.7018  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -2.2286 0.1169  -4.6392  0.1821  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale     -2.0    1.0  -8.6018  4.6018  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.1786 0.1444  -4.5892  0.2321  False\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text    -2.38 0.0475  -4.7501 -0.0099   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.1571    1.0  -2.2535  2.5678  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai   0.3857    1.0  -6.2161  6.9875  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -1.1    1.0 -10.1198  7.9198  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai   0.2133    1.0  -6.3738  6.8004  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock  -0.3933    1.0  -6.9804  6.1938  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai  -1.4067    1.0  -7.9938  5.1804  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale      0.1    1.0  -8.9198  9.1198  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.2286    1.0  -7.8304  5.3732  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -1.0    1.0 -10.0198  8.0198  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1786    1.0  -7.7804  5.4232  False\n",
            "              llama-3-8b-chat@anyscale                          original_text    -1.38    1.0  -7.9671  5.2071  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra   1.1571    1.0  -5.4446  7.7589  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -1.4857    1.0  -8.0875  5.1161  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -0.1724    1.0  -2.5425  2.1977  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock   -0.779    1.0  -3.1492  1.5911  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai  -1.7924 0.4773  -4.1625  0.5777  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.2857    1.0  -6.8875  6.3161  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.6143 0.7292  -4.0249  0.7963  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -1.3857    1.0  -7.9875  5.2161  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.5643 0.7825  -3.9749  0.8463  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  -1.7657 0.5104  -4.1358  0.6044  False\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.7714    1.0  -1.6392  3.1821  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai   1.3133    1.0  -5.2738  7.9004  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock   0.7067    1.0  -5.8804  7.2938  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai  -0.3067    1.0  -6.8938  6.2804  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale      1.2    1.0  -7.8198 10.2198  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -0.1286    1.0  -6.7304  6.4732  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale      0.1    1.0  -8.9198  9.1198  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.0786    1.0  -6.6804  6.5232  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text    -0.28    1.0  -6.8671  6.3071  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   2.2571    1.0  -4.3446  8.8589  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock  -0.6067    1.0  -2.9356  1.7222  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai    -1.62 0.6567  -3.9489  0.7089  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.1133    1.0  -6.7004  6.4738  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.4419   0.87   -3.812  0.9282  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale  -1.2133    1.0  -7.8004  5.3738  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3919 0.9055   -3.762  0.9782  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  -1.5933 0.6893  -3.9222  0.7356  False\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra   0.9438 0.9994  -1.4263  3.3139  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai  -1.0133 0.9977  -3.3422  1.3156  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale   0.4933    1.0  -6.0938  7.0804  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra  -0.8352 0.9999  -3.2054  1.5349  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale  -0.6067    1.0  -7.1938  5.9804  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.7852    1.0  -3.1554  1.5849  False\n",
            "             mistral-large@aws-bedrock                          original_text  -0.9867 0.9985  -3.3156  1.3422  False\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra   1.5505 0.7695  -0.8196  3.9206  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.5067    1.0  -5.0804  8.0938  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.1781    1.0   -2.192  2.5482  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.4067    1.0  -6.1804  6.9938  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.2281    1.0   -2.142  2.5982  False\n",
            "              mistral-small@mistral-ai                          original_text   0.0267    1.0  -2.3022  2.3556  False\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra   2.5638 0.0176   0.1937  4.9339   True\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.3286    1.0  -7.9304  5.2732  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -1.1    1.0 -10.1198  7.9198  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2786    1.0  -7.8804  5.3232  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text    -1.48    1.0  -8.0671  5.1071  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   1.0571    1.0  -5.5446  7.6589  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale   0.2286    1.0  -6.3732  6.8304  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock     0.05    1.0  -2.3606  2.4606  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text  -0.1514    1.0  -2.5215  2.2187  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra   2.3857 0.0566  -0.0249  4.7963  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.1786    1.0  -6.7804  6.4232  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text    -0.38    1.0  -6.9671  6.2071  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   2.1571    1.0  -4.4446  8.7589  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text  -0.2014    1.0  -2.5715  2.1687  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra   2.3357  0.072  -0.0749  4.7463  False\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra   2.5371 0.0204    0.167  4.9073   True\n",
            "---------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tukey's HSD test to compare differences for Coleman-Liau Index\n"
      ],
      "metadata": {
        "id": "62spB5r8EQF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df1 = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['Coleman-Liau Index'].describe()\n",
        "\n",
        "# Tukey's HSD test to compare differences Automated Readability Index\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['Coleman-Liau Index'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_Coleman-Liau Index.xlsx', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2SrmZ_mDrAs",
        "outputId": "e8f3fb09-1a28-49ec-8c70-c128f348e350"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "=====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower    upper  reject\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic   0.2373    1.0  -1.4731  1.9477  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic    2.346 0.9893  -2.4917  7.1837  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic   0.1627    1.0  -1.5477  1.8731  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai    0.276    1.0  -1.4344  1.9864  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai    0.276    1.0  -1.4344  1.9864  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai    0.812 0.9919  -0.8984  2.5224  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai   0.6017    1.0   -1.139  2.3424  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale    2.516 0.9741  -2.3217  7.3537  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai   0.1487    1.0  -1.5617  1.8591  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai   0.0087    1.0  -1.7017  1.7191  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai  -0.3233    1.0  -2.0337  1.3871  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai  -0.0287    1.0  -1.7391  1.6817  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale    2.926 0.8764  -1.9117  7.7637  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai   1.2796 0.5398  -0.4611  3.0202  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale    0.486    1.0  -4.3517  5.3237  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai   0.6396 0.9999  -1.1011  2.3802  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale   -0.564    1.0  -5.4017  4.2737  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai      0.7 0.9991  -1.0104  2.4104  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock   0.4453    1.0  -1.2651  2.1557  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai  -0.4213    1.0  -2.1317  1.2891  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale    0.136    1.0  -4.7017  4.9737  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra    0.031    1.0  -1.7097  1.7717  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   -0.274    1.0  -5.1117  4.5637  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.8983 0.9764   -2.639  0.8424  False\n",
            "              claude-3-haiku@anthropic                          original_text  -2.5253    0.0  -4.2357 -0.8149   True\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra    0.921 0.9683  -0.8197  2.6617  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic   2.1087 0.9976  -2.7291  6.9464  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic  -0.0747    1.0  -1.7851  1.6357  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai   0.0387    1.0  -1.6717  1.7491  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai   0.0387    1.0  -1.6717  1.7491  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai   0.5747    1.0  -1.1357  2.2851  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai   0.3644    1.0  -1.3763  2.1051  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale   2.2787 0.9928  -2.5591  7.1164  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai  -0.0887    1.0  -1.7991  1.6217  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai  -0.2287    1.0  -1.9391  1.4817  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai  -0.5607    1.0  -2.2711  1.1497  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai   -0.266    1.0  -1.9764  1.4444  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale   2.6887 0.9455  -2.1491  7.5264  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai   1.0422  0.887  -0.6984  2.7829  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale   0.2487    1.0  -4.5891  5.0864  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai   0.4022    1.0  -1.3384  2.1429  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale  -0.8013    1.0  -5.6391  4.0364  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   0.4627    1.0  -1.2477  2.1731  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock    0.208    1.0  -1.5024  1.9184  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai  -0.6587 0.9997  -2.3691  1.0517  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale  -0.1013    1.0  -4.9391  4.7364  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.2063    1.0   -1.947  1.5343  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -0.5113    1.0  -5.3491  4.3264  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1356 0.7739  -2.8763  0.6051  False\n",
            "               claude-3-opus@anthropic                          original_text  -2.7627    0.0  -4.4731 -1.0523   True\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra   0.6837 0.9996   -1.057  2.4243  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  -2.1833 0.9961  -7.0211  2.6544  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai    -2.07 0.9982  -6.9077  2.7677  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai    -2.07 0.9982  -6.9077  2.7677  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai   -1.534    1.0  -6.3717  3.3037  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai  -1.7443 0.9999  -6.5928  3.1042  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale     0.17    1.0  -6.4544  6.7944  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai  -2.1973 0.9957  -7.0351  2.6404  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  -2.3373 0.9898  -7.1751  2.5004  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai  -2.6693 0.9495  -7.5071  2.1684  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  -2.3747 0.9874  -7.2124  2.4631  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale     0.58    1.0  -6.0444  7.2044  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai  -1.0664    1.0   -5.915  3.7821  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale    -1.86    1.0  -8.4844  4.7644  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai  -1.7064 0.9999   -6.555  3.1421  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale    -2.91 0.9974  -9.5344  3.7144  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai   -1.646    1.0  -6.4837  3.1917  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock  -1.9007 0.9996  -6.7384  2.9371  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai  -2.7673 0.9267  -7.6051  2.0704  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale    -2.21    1.0  -8.8344  4.4144  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra   -2.315 0.9913  -7.1635  2.5335  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale    -2.62 0.9995  -9.2444  4.0044  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.2443 0.7306  -8.0928  1.6042  False\n",
            "             claude-3-sonnet@anthropic                          original_text  -4.8713  0.046  -9.7091 -0.0336   True\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra   -1.425    1.0  -6.2735  3.4235  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai   0.1133    1.0  -1.5971  1.8237  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai   0.1133    1.0  -1.5971  1.8237  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai   0.6493 0.9998  -1.0611  2.3597  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai    0.439    1.0  -1.3016  2.1797  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale   2.3533 0.9888  -2.4844  7.1911  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai   -0.014    1.0  -1.7244  1.6964  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai   -0.154    1.0  -1.8644  1.5564  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai   -0.486    1.0  -2.1964  1.2244  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai  -0.1913    1.0  -1.9017  1.5191  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale   2.7633 0.9278  -2.0744  7.6011  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai   1.1169 0.7999  -0.6238  2.8576  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale   0.3233    1.0  -4.5144  5.1611  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   0.4769    1.0  -1.2638  2.2176  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale  -0.7267    1.0  -5.5644  4.1111  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5373    1.0  -1.1731  2.2477  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock   0.2827    1.0  -1.4277  1.9931  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai   -0.584    1.0  -2.2944  1.1264  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale  -0.0267    1.0  -4.8644  4.8111  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.1317    1.0  -1.8723   1.609  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -0.4367    1.0  -5.2744  4.4011  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   -1.061 0.8679  -2.8016  0.6797  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text   -2.688    0.0  -4.3984 -0.9776   True\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra   0.7583 0.9977  -0.9823   2.499  False\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai      0.0    1.0  -1.7104  1.7104  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai    0.536    1.0  -1.1744  2.2464  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai   0.3257    1.0   -1.415  2.0664  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale     2.24 0.9943  -2.5977  7.0777  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai  -0.1273    1.0  -1.8377  1.5831  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai  -0.2673    1.0  -1.9777  1.4431  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai  -0.5993 0.9999  -2.3097  1.1111  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai  -0.3047    1.0  -2.0151  1.4057  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale     2.65 0.9533  -2.1877  7.4877  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai   1.0036 0.9208  -0.7371  2.7442  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale     0.21    1.0  -4.6277  5.0477  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai   0.3636    1.0  -1.3771  2.1042  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale    -0.84    1.0  -5.6777  3.9977  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai    0.424    1.0  -1.2864  2.1344  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock   0.1693    1.0  -1.5411  1.8797  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai  -0.6973 0.9992  -2.4077  1.0131  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale    -0.14    1.0  -4.9777  4.6977  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.245    1.0  -1.9857  1.4957  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale    -0.55    1.0  -5.3877  4.2877  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1743 0.7158   -2.915  0.5664  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text  -2.8013    0.0  -4.5117 -1.0909   True\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra    0.645 0.9998  -1.0957  2.3857  False\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai    0.536    1.0  -1.1744  2.2464  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai   0.3257    1.0   -1.415  2.0664  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale     2.24 0.9943  -2.5977  7.0777  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai  -0.1273    1.0  -1.8377  1.5831  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai  -0.2673    1.0  -1.9777  1.4431  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai  -0.5993 0.9999  -2.3097  1.1111  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai  -0.3047    1.0  -2.0151  1.4057  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale     2.65 0.9533  -2.1877  7.4877  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai   1.0036 0.9208  -0.7371  2.7442  False\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale     0.21    1.0  -4.6277  5.0477  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai   0.3636    1.0  -1.3771  2.1042  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale    -0.84    1.0  -5.6777  3.9977  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai    0.424    1.0  -1.2864  2.1344  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock   0.1693    1.0  -1.5411  1.8797  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai  -0.6973 0.9992  -2.4077  1.0131  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale    -0.14    1.0  -4.9777  4.6977  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.245    1.0  -1.9857  1.4957  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale    -0.55    1.0  -5.3877  4.2877  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1743 0.7158   -2.915  0.5664  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text  -2.8013    0.0  -4.5117 -1.0909   True\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra    0.645 0.9998  -1.0957  2.3857  False\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai  -0.2103    1.0   -1.951  1.5304  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale    1.704 0.9999  -3.1337  6.5417  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai  -0.6633 0.9996  -2.3737  1.0471  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai  -0.8033  0.993  -2.5137  0.9071  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai  -1.1353 0.7448  -2.8457  0.5751  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai  -0.8407 0.9872  -2.5511  0.8697  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale    2.114 0.9976  -2.7237  6.9517  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai   0.4676    1.0  -1.2731  2.2082  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale   -0.326    1.0  -5.1637  4.5117  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai  -0.1724    1.0  -1.9131  1.5682  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   -1.376    1.0  -6.2137  3.4617  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   -0.112    1.0  -1.8224  1.5984  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock  -0.3667    1.0  -2.0771  1.3437  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai  -1.2333 0.5817  -2.9437  0.4771  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   -0.676    1.0  -5.5137  4.1617  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.781 0.9964  -2.5217  0.9597  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   -1.086    1.0  -5.9237  3.7517  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.7103 0.0615   -3.451  0.0304  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text  -3.3373    0.0  -5.0477 -1.6269   True\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra    0.109    1.0  -1.6317  1.8497  False\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale   1.9143 0.9995  -2.9342  6.7628  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai   -0.453    1.0  -2.1937  1.2876  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai   -0.593    1.0  -2.3337  1.1476  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai   -0.925 0.9667  -2.6657  0.8156  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai  -0.6304 0.9999  -2.3711  1.1103  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale   2.3243 0.9908  -2.5242  7.1728  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai   0.6779 0.9997  -1.0926  2.4483  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale  -0.1157    1.0  -4.9642  4.7328  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai   0.0379    1.0  -1.7326  1.8083  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale  -1.1657    1.0  -6.0142  3.6828  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai   0.0983    1.0  -1.6424   1.839  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock  -0.1564    1.0  -1.8971  1.5843  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai   -1.023 0.9048  -2.7637  0.7176  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.4657    1.0  -5.3142  4.3828  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5707    1.0  -2.3411  1.1997  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.8757    1.0  -5.7242  3.9728  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock     -1.5  0.244  -3.2704  0.2704  False\n",
            "               gemma-2b-it@together-ai                          original_text   -3.127    0.0  -4.8677 -1.3864   True\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra   0.3193    1.0  -1.4511  2.0897  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai  -2.3673 0.9879  -7.2051  2.4704  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  -2.5073 0.9752  -7.3451  2.3304  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai  -2.8393  0.906  -7.6771  1.9984  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  -2.5447 0.9704  -7.3824  2.2931  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale     0.41    1.0  -6.2144  7.0344  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai  -1.2364    1.0   -6.085  3.6121  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale    -2.03    1.0  -8.6544  4.5944  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai  -1.8764 0.9997   -6.725  2.9721  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale    -3.08  0.994  -9.7044  3.5444  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai   -1.816 0.9998  -6.6537  3.0217  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  -2.0707 0.9982  -6.9084  2.7671  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai  -2.9373 0.8722  -7.7751  1.9004  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale    -2.38 0.9999  -9.0044  4.2444  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   -2.485 0.9783  -7.3335  2.3635  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale    -2.79 0.9986  -9.4144  3.8344  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.4143 0.6317  -8.2628  1.4342  False\n",
            "                  gemma-7b-it@anyscale                          original_text  -5.0413 0.0296  -9.8791 -0.2036   True\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra   -1.595    1.0  -6.4435  3.2535  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai    -0.14    1.0  -1.8504  1.5704  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai   -0.472    1.0  -2.1824  1.2384  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai  -0.1773    1.0  -1.8877  1.5331  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale   2.7773  0.924  -2.0604  7.6151  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai   1.1309 0.7806  -0.6098  2.8716  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale   0.3373    1.0  -4.5004  5.1751  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai   0.4909    1.0  -1.2498  2.2316  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale  -0.7127    1.0  -5.5504  4.1251  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai   0.5513    1.0  -1.1591  2.2617  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock   0.2967    1.0  -1.4137  2.0071  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai    -0.57    1.0  -2.2804  1.1404  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale  -0.0127    1.0  -4.8504  4.8251  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.1177    1.0  -1.8583   1.623  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale  -0.4227    1.0  -5.2604  4.4151  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   -1.047 0.8824  -2.7876  0.6937  False\n",
            "                  gpt-3.5-turbo@openai                          original_text   -2.674    0.0  -4.3844 -0.9636   True\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra   0.7723 0.9969  -0.9683   2.513  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai   -0.332    1.0  -2.0424  1.3784  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai  -0.0373    1.0  -1.7477  1.6731  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale   2.9173 0.8796  -1.9204  7.7551  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai   1.2709 0.5547  -0.4698  3.0116  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale   0.4773    1.0  -4.3604  5.3151  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai   0.6309 0.9999  -1.1098  2.3716  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale  -0.5727    1.0  -5.4104  4.2651  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai   0.6913 0.9993  -1.0191  2.4017  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock   0.4367    1.0  -1.2737  2.1471  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai    -0.43    1.0  -2.1404  1.2804  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.1273    1.0  -4.7104  4.9651  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.0223    1.0  -1.7183   1.763  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale  -0.2827    1.0  -5.1204  4.5551  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.907 0.9736  -2.6476  0.8337  False\n",
            "                    gpt-4-turbo@openai                          original_text   -2.534    0.0  -4.2444 -0.8236   True\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   0.9123 0.9716  -0.8283   2.653  False\n",
            "                          gpt-4@openai                          gpt-4o@openai   0.2947    1.0  -1.4157  2.0051  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale   3.2493 0.7238  -1.5884  8.0871  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai   1.6029 0.1214  -0.1378  3.3436  False\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale   0.8093    1.0  -4.0284  5.6471  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai   0.9629 0.9481  -0.7778  2.7036  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale  -0.2407    1.0  -5.0784  4.5971  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai   1.0233 0.8878  -0.6871  2.7337  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock   0.7687 0.9963  -0.9417  2.4791  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai   -0.098    1.0  -1.8084  1.6124  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.4593    1.0  -4.3784  5.2971  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.3543    1.0  -1.3863   2.095  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale   0.0493    1.0  -4.7884  4.8871  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.575    1.0  -2.3156  1.1657  False\n",
            "                          gpt-4@openai                          original_text   -2.202 0.0008  -3.9124 -0.4916   True\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra   1.2443 0.6002  -0.4963   2.985  False\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale   2.9547 0.8655  -1.8831  7.7924  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai   1.3082  0.491  -0.4324  3.0489  False\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale   0.5147    1.0  -4.3231  5.3524  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai   0.6682 0.9997  -1.0724  2.4089  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale  -0.5353    1.0  -5.3731  4.3024  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai   0.7287 0.9983  -0.9817  2.4391  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock    0.474    1.0  -1.2364  2.1844  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai  -0.3927    1.0  -2.1031  1.3177  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.1647    1.0  -4.6731  5.0024  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.0597    1.0   -1.681  1.8003  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale  -0.2453    1.0  -5.0831  4.5924  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.8696 0.9842  -2.6103  0.8711  False\n",
            "                         gpt-4o@openai                          original_text  -2.4967    0.0  -4.2071 -0.7863   True\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra   0.9497 0.9553   -0.791  2.6903  False\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai  -1.6464    1.0   -6.495  3.2021  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale    -2.44 0.9999  -9.0644  4.1844  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -2.2864 0.9926   -7.135  2.5621  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale    -3.49 0.9699 -10.1144  3.1344  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai   -2.226 0.9948  -7.0637  2.6117  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  -2.4807 0.9782  -7.3184  2.3571  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai  -3.3473 0.6673  -8.1851  1.4904  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale    -2.79 0.9986  -9.4144  3.8344  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   -2.895 0.8898  -7.7435  1.9535  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -3.2 0.9898  -9.8244  3.4244  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.8243 0.3854  -8.6728  1.0242  False\n",
            "             llama-3-70b-chat@anyscale                          original_text  -5.4513 0.0094 -10.2891 -0.6136   True\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra   -2.005  0.999  -6.8535  2.8435  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale  -0.7936    1.0  -5.6421   4.055  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai    -0.64 0.9999  -2.4104  1.1304  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -1.8436 0.9997  -6.6921   3.005  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -0.5796    1.0  -2.3202  1.1611  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.8342 0.9908  -2.5749  0.9064  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai  -1.7009 0.0655  -3.4416  0.0398  False\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -1.1436    1.0  -5.9921   3.705  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.2486 0.6286   -3.019  0.5219  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -1.5536    1.0  -6.4021   3.295  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.1779  0.002  -3.9483 -0.4074   True\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text  -3.8049    0.0  -5.5456 -2.0642   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra  -0.3586    1.0   -2.129  1.4119  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai   0.1536    1.0   -4.695  5.0021  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale    -1.05    1.0  -7.6744  5.5744  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai    0.214    1.0  -4.6237  5.0517  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock  -0.0407    1.0  -4.8784  4.7971  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai  -0.9073    1.0  -5.7451  3.9304  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale    -0.35    1.0  -6.9744  6.2744  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   -0.455    1.0  -5.3035  4.3935  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale    -0.76    1.0  -7.3844  5.8644  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3843    1.0  -6.2328  3.4642  False\n",
            "              llama-3-8b-chat@anyscale                          original_text  -3.0113 0.8424  -7.8491  1.8264  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra    0.435    1.0  -4.4135  5.2835  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -1.2036    1.0  -6.0521   3.645  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   0.0604    1.0  -1.6802  1.8011  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.1942    1.0  -1.9349  1.5464  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai  -1.0609 0.8679  -2.8016  0.6798  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.5036    1.0  -5.3521   4.345  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.6086    1.0   -2.379  1.1619  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.9136    1.0  -5.7621   3.935  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.5379 0.2019  -3.3083  0.2326  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  -3.1649    0.0  -4.9056 -1.4242   True\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.2814    1.0   -1.489  2.0519  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai    1.264    1.0  -3.5737  6.1017  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock   1.0093    1.0  -3.8284  5.8471  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai   0.1427    1.0  -4.6951  4.9804  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale      0.7    1.0  -5.9244  7.3244  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra    0.595    1.0  -4.2535  5.4435  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     0.29    1.0  -6.3344  6.9144  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.3343    1.0  -5.1828  4.5142  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text  -1.9613 0.9993  -6.7991  2.8764  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra    1.485    1.0  -3.3635  6.3335  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock  -0.2547    1.0  -1.9651  1.4557  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai  -1.1213 0.7659  -2.8317  0.5891  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   -0.564    1.0  -5.4017  4.2737  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.669 0.9997  -2.4097  1.0717  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   -0.974    1.0  -5.8117  3.8637  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.5983 0.1248   -3.339  0.1424  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  -3.2253    0.0  -4.9357 -1.5149   True\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra    0.221    1.0  -1.5197  1.9617  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai  -0.8667 0.9811  -2.5771  0.8437  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale  -0.3093    1.0  -5.1471  4.5284  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra  -0.4143    1.0   -2.155  1.3263  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale  -0.7193    1.0  -5.5571  4.1184  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3436 0.4322  -3.0843  0.3971  False\n",
            "             mistral-large@aws-bedrock                          original_text  -2.9707    0.0  -4.6811 -1.2603   True\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra   0.4757    1.0   -1.265  2.2163  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.5573    1.0  -4.2804  5.3951  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.4523    1.0  -1.2883   2.193  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.1473    1.0  -4.6904  4.9851  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.477    1.0  -2.2176  1.2637  False\n",
            "              mistral-small@mistral-ai                          original_text   -2.104  0.002  -3.8144 -0.3936   True\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra   1.3423 0.4343  -0.3983   3.083  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   -0.105    1.0  -4.9535  4.7435  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale    -0.41    1.0  -7.0344  6.2144  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.0343    1.0  -5.8828  3.8142  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text  -2.6613 0.9511  -7.4991  2.1764  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra    0.785    1.0  -4.0635  5.6335  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale   -0.305    1.0  -5.1535  4.5435  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.9293 0.9711  -2.6997  0.8411  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text  -2.5563    0.0   -4.297 -0.8157   True\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra     0.89 0.9829  -0.8804  2.6604  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.6243    1.0  -5.4728  4.2242  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text  -2.2513 0.9939  -7.0891  2.5864  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra    1.195    1.0  -3.6535  6.0435  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text   -1.627 0.1049  -3.3677  0.1136  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra   1.8193 0.0356   0.0489  3.5897   True\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra   3.4463    0.0   1.7057   5.187   True\n",
            "---------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tukey's HSD test to compare differences for Flesch Reading Ease"
      ],
      "metadata": {
        "id": "OQdipAiIGb-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['Flesch Reading Ease'].describe()\n",
        "\n",
        "# Tukey's HSD test to compare differences Flesch Reading Ease\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['Flesch Reading Ease'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_Flesch Reading Ease.xlsx', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NqM_2tNEzrt",
        "outputId": "8546e3a9-924b-48ab-c747-5f7ec1f77f4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "=====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower    upper  reject\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic  -1.5593    1.0 -10.3735  7.2548  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic -10.5047 0.9986 -35.4349 14.4255  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic   0.9967    1.0  -7.8175  9.8108  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai    0.814    1.0  -8.0002  9.6282  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai  -0.0133    1.0  -8.8275  8.8008  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai     1.13    1.0  -7.6842  9.9442  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai  -2.3361    1.0 -11.3063  6.6341  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale -13.1747 0.9688 -38.1049 11.7555  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai  -3.0087    1.0 -11.8228  5.8055  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai     1.88    1.0  -6.9342 10.6942  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai   1.2013    1.0  -7.6128 10.0155  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai     1.34    1.0  -7.4742 10.1542  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale -17.1347 0.6804 -42.0649  7.7955  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai  -4.9511 0.9493 -13.9213  4.0191  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale  -6.6447    1.0 -31.5749 18.2855  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai  -3.9254 0.9975 -12.8955  5.0448  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale  -6.7447    1.0 -31.6749 18.1855  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai  -2.8933    1.0 -11.7075  5.9208  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock  -2.4473    1.0 -11.2615  6.3668  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai   1.2807    1.0  -7.5335 10.0948  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   0.0953    1.0 -24.8349 25.0255  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra   0.8896    1.0  -8.0805  9.8598  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -6.1347    1.0 -31.0649 18.7955  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock    4.096 0.9953  -4.8741 13.0662  False\n",
            "              claude-3-haiku@anthropic                          original_text   10.382 0.0044   1.5678 19.1962   True\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra   -5.739 0.8043 -14.7091  3.2312  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic  -8.9453 0.9999 -33.8755 15.9849  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic    2.556    1.0  -6.2582 11.3702  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai   2.3733    1.0  -6.4408 11.1875  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai    1.546    1.0  -7.2682 10.3602  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai   2.6893    1.0  -6.1248 11.5035  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai  -0.7768    1.0  -9.7469  8.1934  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale -11.6153 0.9938 -36.5455 13.3149  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai  -1.4493    1.0 -10.2635  7.3648  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai   3.4393 0.9996  -5.3748 12.2535  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai   2.7607    1.0  -6.0535 11.5748  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai   2.8993    1.0  -5.9148 11.7135  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale -15.5753 0.8376 -40.5055  9.3549  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai  -3.3918 0.9998 -12.3619  5.5784  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale  -5.0853    1.0 -30.0155 19.8449  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai   -2.366    1.0 -11.3362  6.6041  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale  -5.1853    1.0 -30.1155 19.7449  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   -1.334    1.0 -10.1482  7.4802  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock   -0.888    1.0  -9.7022  7.9262  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai     2.84    1.0  -5.9742 11.6542  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   1.6547    1.0 -23.2755 26.5849  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra    2.449    1.0  -6.5212 11.4191  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -4.5753    1.0 -29.5055 20.3549  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   5.6554 0.8253  -3.3148 14.6255  False\n",
            "               claude-3-opus@anthropic                          original_text  11.9413 0.0002   3.1272 20.7555   True\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra  -4.1796 0.9938 -13.1498  4.7905  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  11.5013 0.9946 -13.4289 36.4315  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai  11.3187 0.9957 -13.6115 36.2489  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai  10.4913 0.9986 -14.4389 35.4215  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  11.6347 0.9936 -13.2955 36.5649  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai   8.1686    1.0 -16.8172 33.1543  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale    -2.67    1.0 -36.8071 31.4671  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai    7.496    1.0 -17.4342 32.4262  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  12.3847 0.9853 -12.5455 37.3149  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai   11.706 0.9931 -13.2242 36.6362  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  11.8447 0.9919 -13.0855 36.7749  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale    -6.63    1.0 -40.7671 27.5071  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai   5.5536    1.0 -19.4322 30.5393  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale     3.86    1.0 -30.2771 37.9971  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   6.5793    1.0 -18.4065 31.5651  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale     3.76    1.0 -30.3771 37.8971  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai   7.6113    1.0 -17.3189 32.5415  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock   8.0573    1.0 -16.8729 32.9875  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai  11.7853 0.9924 -13.1449 36.7155  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     10.6    1.0 -23.5371 44.7371  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  11.3943 0.9954 -13.5915 36.3801  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     4.37    1.0 -29.7671 38.5071  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  14.6007 0.9098 -10.3851 39.5865  False\n",
            "             claude-3-sonnet@anthropic                          original_text  20.8867 0.2643  -4.0435 45.8169  False\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra   4.7657    1.0 -20.2201 29.7515  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -0.1827    1.0  -8.9968  8.6315  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai    -1.01    1.0  -9.8242  7.8042  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai   0.1333    1.0  -8.6808  8.9475  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai  -3.3328 0.9998 -12.3029  5.6374  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale -14.1713 0.9312 -39.1015 10.7589  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai  -4.0053 0.9956 -12.8195  4.8088  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai   0.8833    1.0  -7.9308  9.6975  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai   0.2047    1.0  -8.6095  9.0188  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai   0.3433    1.0  -8.4708  9.1575  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale -18.1313 0.5631 -43.0615  6.7989  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai  -5.9478 0.7467 -14.9179  3.0224  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale  -7.6413    1.0 -32.5715 17.2889  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   -4.922 0.9524 -13.8922  4.0481  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale  -7.7413    1.0 -32.6715 17.1889  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai    -3.89 0.9972 -12.7042  4.9242  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock   -3.444 0.9996 -12.2582  5.3702  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai    0.284    1.0  -8.5302  9.0982  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale  -0.9013    1.0 -25.8315 24.0289  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra   -0.107    1.0  -9.0772  8.8631  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale  -7.1313    1.0 -32.0615 17.7989  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock   3.0994    1.0  -5.8708 12.0695  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text   9.3853  0.022   0.5712 18.1995   True\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra  -6.7356  0.493 -15.7058  2.2345  False\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai  -0.8273    1.0  -9.6415  7.9868  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai    0.316    1.0  -8.4982  9.1302  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai  -3.1501 0.9999 -12.1203  5.8201  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale -13.9887 0.9397 -38.9189 10.9415  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai  -3.8227 0.9978 -12.6368  4.9915  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai    1.066    1.0  -7.7482  9.8802  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai   0.3873    1.0  -8.4268  9.2015  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai    0.526    1.0  -8.2882  9.3402  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale -17.9487  0.585 -42.8789  6.9815  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai  -5.7651 0.7975 -14.7353  3.2051  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale  -7.4587    1.0 -32.3889 17.4715  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai  -4.7394 0.9689 -13.7095  4.2308  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale  -7.5587    1.0 -32.4889 17.3715  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai  -3.7073 0.9986 -12.5215  5.1068  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock  -3.2613 0.9998 -12.0755  5.5528  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai   0.4667    1.0  -8.3475  9.2808  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.7187    1.0 -25.6489 24.2115  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.0756    1.0  -8.8945  9.0458  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale  -6.9487    1.0 -31.8789 17.9815  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    3.282 0.9999  -5.6881 12.2522  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text    9.568 0.0167   0.7538 18.3822   True\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra   -6.553 0.5535 -15.5231  2.4172  False\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai   1.1433    1.0  -7.6708  9.9575  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai  -2.3228    1.0 -11.2929  6.6474  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale -13.1613 0.9691 -38.0915 11.7689  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai  -2.9953    1.0 -11.8095  5.8188  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai   1.8933    1.0  -6.9208 10.7075  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai   1.2147    1.0  -7.5995 10.0288  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai   1.3533    1.0  -7.4608 10.1675  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale -17.1213  0.682 -42.0515  7.8089  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai  -4.9378 0.9508 -13.9079  4.0324  False\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale  -6.6313    1.0 -31.5615 18.2989  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai   -3.912 0.9976 -12.8822  5.0581  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale  -6.7313    1.0 -31.6615 18.1989  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai    -2.88    1.0 -11.6942  5.9342  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock   -2.434    1.0 -11.2482  6.3802  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai    1.294    1.0  -7.5202 10.1082  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.1087    1.0 -24.8215 25.0389  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra    0.903    1.0  -8.0672  9.8731  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale  -6.1213    1.0 -31.0515 18.8089  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   4.1094 0.9951  -4.8608 13.0795  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text  10.3953 0.0043   1.5812 19.2095   True\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra  -5.7256 0.8077 -14.6958  3.2445  False\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai  -3.4661 0.9997 -12.4363  5.5041  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale -14.3047 0.9244 -39.2349 10.6255  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai  -4.1387 0.9931 -12.9528  4.6755  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai     0.75    1.0  -8.0642  9.5642  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai   0.0713    1.0  -8.7428  8.8855  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai     0.21    1.0  -8.6042  9.0242  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale -18.2647 0.5472 -43.1949  6.6655  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai  -6.0811 0.7067 -15.0513  2.8891  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale  -7.7747    1.0 -32.7049 17.1555  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai  -5.0554 0.9369 -14.0255  3.9148  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -7.8747    1.0 -32.8049 17.0555  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -4.0233 0.9954 -12.8375  4.7908  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock  -3.5773 0.9992 -12.3915  5.2368  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai   0.1507    1.0  -8.6635  8.9648  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -1.0347    1.0 -25.9649 23.8955  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.2404    1.0  -9.2105  8.7298  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -7.2647    1.0 -32.1949 17.6655  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    2.966    1.0  -6.0041 11.9362  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text    9.252 0.0269   0.4378 18.0662   True\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra   -6.869 0.4497 -15.8391  2.1012  False\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale -10.8386 0.9978 -35.8243 14.1472  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai  -0.6726    1.0  -9.6427  8.2976  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai   4.2161  0.993  -4.7541 13.1863  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai   3.5374 0.9995  -5.4327 12.5076  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai   3.6761 0.9991  -5.2941 12.6463  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale -14.7986 0.8977 -39.7843 10.1872  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai   -2.615    1.0 -11.7385  6.5085  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale  -4.3086    1.0 -29.2943 20.6772  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai  -1.5893    1.0 -10.7128  7.5342  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale  -4.4086    1.0 -29.3943 20.5772  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai  -0.5572    1.0  -9.5274  8.4129  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock  -0.1112    1.0  -9.0814  8.8589  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai   3.6168 0.9993  -5.3534 12.5869  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   2.4314    1.0 -22.5543 27.4172  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra   3.2257 0.9999  -5.8978 12.3492  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale  -3.7986    1.0 -28.7843 21.1872  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   6.4321 0.6293  -2.6914 15.5557  False\n",
            "               gemma-2b-it@together-ai                          original_text  12.7181 0.0001   3.7479 21.6883   True\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra  -3.4029 0.9998 -12.5264  5.7207  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai   10.166 0.9992 -14.7642 35.0962  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  15.0547 0.8781  -9.8755 39.9849  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai   14.376 0.9207 -10.5542 39.3062  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  14.5147 0.9129 -10.4155 39.4449  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale    -3.96    1.0 -38.0971 30.1771  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai   8.2236    1.0 -16.7622 33.2093  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale     6.53    1.0 -27.6071 40.6671  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai   9.2493 0.9998 -15.7365 34.2351  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale     6.43    1.0 -27.7071 40.5671  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai  10.2813  0.999 -14.6489 35.2115  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  10.7273 0.9981 -14.2029 35.6575  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai  14.4553 0.9163 -10.4749 39.3855  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale    13.27 0.9996 -20.8671 47.4071  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  14.0643 0.9377 -10.9215 39.0501  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     7.04    1.0 -27.0971 41.1771  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  17.2707 0.6693  -7.7151 42.2565  False\n",
            "                  gemma-7b-it@anyscale                          original_text  23.5567  0.094  -1.3735 48.4869  False\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra   7.4357    1.0 -17.5501 32.4215  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai   4.8887 0.9466  -3.9255 13.7028  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai     4.21 0.9912  -4.6042 13.0242  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai   4.3487 0.9866  -4.4655 13.1628  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale  -14.126 0.9334 -39.0562 10.8042  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai  -1.9424    1.0 -10.9126  7.0277  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale   -3.636    1.0 -28.5662 21.2942  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai  -0.9167    1.0  -9.8869  8.0535  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale   -3.736    1.0 -28.6662 21.1942  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai   0.1153    1.0  -8.6988  8.9295  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock   0.5613    1.0  -8.2528  9.3755  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai   4.2893 0.9888  -4.5248 13.1035  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale    3.104    1.0 -21.8262 28.0342  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra   3.8983 0.9978  -5.0719 12.8685  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale   -3.126    1.0 -28.0562 21.8042  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   7.1047 0.3765  -1.8655 16.0749  False\n",
            "                  gpt-3.5-turbo@openai                          original_text  13.3907    0.0   4.5765 22.2048   True\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra  -2.7303    1.0 -11.7005  6.2399  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai  -0.6787    1.0  -9.4928  8.1355  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai    -0.54    1.0  -9.3542  8.2742  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale -19.0147 0.4585 -43.9449  5.9155  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai  -6.8311 0.4619 -15.8013  2.1391  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale  -8.5247    1.0 -33.4549 16.4055  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai  -5.8054 0.7867 -14.7755  3.1648  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale  -8.6247    1.0 -33.5549 16.3055  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai  -4.7733 0.9588 -13.5875  4.0408  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock  -4.3273 0.9874 -13.1415  4.4868  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai  -0.5993    1.0  -9.4135  8.2148  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale  -1.7847    1.0 -26.7149 23.1455  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.9904    1.0  -9.9605  7.9798  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale  -8.0147    1.0 -32.9449 16.9155  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock    2.216    1.0  -6.7541 11.1862  False\n",
            "                    gpt-4-turbo@openai                          original_text    8.502 0.0756  -0.3122 17.3162  False\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   -7.619 0.2396 -16.5891  1.3512  False\n",
            "                          gpt-4@openai                          gpt-4o@openai   0.1387    1.0  -8.6755  8.9528  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale  -18.336 0.5386 -43.2662  6.5942  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai  -6.1524 0.6845 -15.1226  2.8177  False\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale   -7.846    1.0 -32.7762 17.0842  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai  -5.1267 0.9273 -14.0969  3.8435  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale   -7.946    1.0 -32.8762 16.9842  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai  -4.0947  0.994 -12.9088  4.7195  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock  -3.6487 0.9989 -12.4628  5.1655  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai   0.0793    1.0  -8.7348  8.8935  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale   -1.106    1.0 -26.0362 23.8242  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.3117    1.0  -9.2819  8.6585  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale   -7.336    1.0 -32.2662 17.5942  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   2.8947    1.0  -6.0755 11.8649  False\n",
            "                          gpt-4@openai                          original_text   9.1807 0.0298   0.3665 17.9948   True\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra  -6.9403  0.427 -15.9105  2.0299  False\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale -18.4747 0.5221 -43.4049  6.4555  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai  -6.2911   0.64 -15.2613  2.6791  False\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale  -7.9847    1.0 -32.9149 16.9455  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai  -5.2654 0.9059 -14.2355  3.7048  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale  -8.0847    1.0 -33.0149 16.8455  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai  -4.2333 0.9906 -13.0475  4.5808  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock  -3.7873 0.9981 -12.6015  5.0268  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai  -0.0593    1.0  -8.8735  8.7548  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale  -1.2447    1.0 -26.1749 23.6855  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.4504    1.0  -9.4205  8.5198  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale  -7.4747    1.0 -32.4049 17.4555  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock    2.756    1.0  -6.2141 11.7262  False\n",
            "                         gpt-4o@openai                          original_text    9.042 0.0364   0.2278 17.8562   True\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra   -7.079 0.3843 -16.0491  1.8912  False\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai  12.1836 0.9885 -12.8022 37.1693  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale    10.49    1.0 -23.6471 44.6271  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  13.2093 0.9686 -11.7765 38.1951  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale    10.39    1.0 -23.7471 44.5271  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  14.2413 0.9277 -10.6889 39.1715  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  14.6873 0.9026 -10.2429 39.6175  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai  18.4153 0.5292  -6.5149 43.3455  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale    17.23  0.982 -16.9071 51.3671  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  18.0243 0.5808  -6.9615 43.0101  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     11.0    1.0 -23.1371 45.1371  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  21.2307 0.2389  -3.7551 46.2165  False\n",
            "             llama-3-70b-chat@anyscale                          original_text  27.5167  0.013   2.5865 52.4469   True\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra  11.3957 0.9954 -13.5901 36.3815  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale  -1.6936    1.0 -26.6793 23.2922  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai   1.0257    1.0  -8.0978 10.1492  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -1.7936    1.0 -26.7793 23.1922  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   2.0578    1.0  -6.9124 11.0279  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock   2.5038    1.0  -6.4664 11.4739  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai   6.2318 0.6592  -2.7384 15.2019  False\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   5.0464    1.0 -19.9393 30.0322  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra   5.8407 0.8034  -3.2828 14.9642  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -1.1836    1.0 -26.1693 23.8022  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   9.0471 0.0553  -0.0764 18.1707  False\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text  15.3331    0.0   6.3629 24.3033   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra  -0.7879    1.0  -9.9114  8.3357  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai   2.7193    1.0 -22.2665 27.7051  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -0.1    1.0 -34.2371 34.0371  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai   3.7513    1.0 -21.1789 28.6815  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock   4.1973    1.0 -20.7329 29.1275  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai   7.9253    1.0 -17.0049 32.8555  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     6.74    1.0 -27.3971 40.8771  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   7.5343    1.0 -17.4515 32.5201  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     0.51    1.0 -33.6271 34.6471  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  10.7407 0.9981 -14.2451 35.7265  False\n",
            "              llama-3-8b-chat@anyscale                          original_text  17.0267 0.6927  -7.9035 41.9569  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra   0.9057    1.0 -24.0801 25.8915  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale  -2.8193    1.0 -27.8051 22.1665  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai    1.032    1.0  -7.9381 10.0022  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock    1.478    1.0  -7.4921 10.4482  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai    5.206 0.9155  -3.7641 14.1762  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   4.0207    1.0 -20.9651 29.0065  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra    4.815 0.9693  -4.3085 13.9385  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -2.2093    1.0 -27.1951 22.7765  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   8.0214 0.1831  -1.1021 17.1449  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  14.3074    0.0   5.3372 23.2775   True\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra  -1.8136    1.0 -10.9371  7.3099  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai   3.8513    1.0 -21.0789 28.7815  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock   4.2973    1.0 -20.6329 29.2275  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai   8.0253    1.0 -16.9049 32.9555  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     6.84    1.0 -27.2971 40.9771  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   7.6343    1.0 -17.3515 32.6201  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     0.61    1.0 -33.5271 34.7471  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  10.8407 0.9978 -14.1451 35.8265  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text  17.1267 0.6814  -7.8035 42.0569  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   1.0057    1.0 -23.9801 25.9915  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock    0.446    1.0  -8.3682  9.2602  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai    4.174 0.9922  -4.6402 12.9882  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   2.9887    1.0 -21.9415 27.9189  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra    3.783 0.9986  -5.1872 12.7531  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale  -3.2413    1.0 -28.1715 21.6889  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   6.9894 0.4117  -1.9808 15.9595  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  13.2753    0.0   4.4612 22.0895   True\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra  -2.8456    1.0 -11.8158  6.1245  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai    3.728 0.9985  -5.0862 12.5422  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale   2.5427    1.0 -22.3875 27.4729  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra    3.337 0.9998  -5.6332 12.3071  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale  -3.6873    1.0 -28.6175 21.2429  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock   6.5434 0.5566  -2.4268 15.5135  False\n",
            "             mistral-large@aws-bedrock                          original_text  12.8293    0.0   4.0152 21.6435   True\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra  -3.2916 0.9999 -12.2618  5.6785  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale  -1.1853    1.0 -26.1155 23.7449  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.391    1.0  -9.3612  8.5791  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale  -7.4153    1.0 -32.3455 17.5149  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   2.8154    1.0  -6.1548 11.7855  False\n",
            "              mistral-small@mistral-ai                          original_text   9.1013 0.0334   0.2872 17.9155   True\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra  -7.0196 0.4023 -15.9898  1.9505  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra   0.7943    1.0 -24.1915 25.7801  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale    -6.23    1.0 -40.3671 27.9071  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock   4.0007    1.0 -20.9851 28.9865  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text  10.2867  0.999 -14.6435 35.2169  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra  -5.8343    1.0 -30.8201 19.1515  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale  -7.0243    1.0 -32.0101 17.9615  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock   3.2064 0.9999  -5.9171 12.3299  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text   9.4924  0.024   0.5222 18.4625   True\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra  -6.6286 0.5654 -15.7521  2.4949  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  10.2307 0.9991 -14.7551 35.2165  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text  16.5167 0.7481  -8.4135 41.4469  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.3957    1.0 -24.5901 25.3815  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text    6.286 0.6417  -2.6842 15.2561  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra   -9.835 0.0185 -18.9585 -0.7115   True\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra  -16.121    0.0 -25.0911 -7.1508   True\n",
            "---------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tukey's HSD test to compare differences for Flesch-Kincaid Grade Level"
      ],
      "metadata": {
        "id": "nBxQIYagGlPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df_new[~df_new['model'].isin(exclude_models)]\n",
        "\n",
        "summary_table = filtered_df.groupby('model')['Flesch-Kincaid Grade Level'].describe()\n",
        "\n",
        "# Tukey's HSD test to compare differences Flesch-Kincaid Grade Level\n",
        "tukey = mc.pairwise_tukeyhsd(filtered_df['Flesch-Kincaid Grade Level'], filtered_df['model'])\n",
        "\n",
        "print(tukey.summary())\n",
        "tukey_summary_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
        "tukey_summary_df.to_excel('tukey_summary_Flesch-Kincaid Grade Levele.xlsx', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLOW7H5JGH-Z",
        "outputId": "dd91be1a-4069-43ee-c5cb-abea5f8981c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Multiple Comparison of Means - Tukey HSD, FWER=0.05                                 \n",
            "====================================================================================================================\n",
            "                group1                                 group2                 meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------------------------------------------------------------\n",
            "              claude-3-haiku@anthropic                claude-3-opus@anthropic   0.0333    1.0 -1.8538  1.9204  False\n",
            "              claude-3-haiku@anthropic              claude-3-sonnet@anthropic     2.54 0.9917 -2.7975  7.8775  False\n",
            "              claude-3-haiku@anthropic            claude-3.5-sonnet@anthropic  -0.6533    1.0 -2.5404  1.2338  False\n",
            "              claude-3-haiku@anthropic             gemini-1.5-flash@vertex-ai  -0.5867    1.0 -2.4738  1.3004  False\n",
            "              claude-3-haiku@anthropic               gemini-1.5-pro@vertex-ai  -0.8267 0.9975 -2.7138  1.0604  False\n",
            "              claude-3-haiku@anthropic             gemma-2-9b-it@fireworks-ai  -0.8533 0.9959 -2.7404  1.0338  False\n",
            "              claude-3-haiku@anthropic                gemma-2b-it@together-ai   0.2543    1.0 -1.6662  2.1748  False\n",
            "              claude-3-haiku@anthropic                   gemma-7b-it@anyscale     1.44    1.0 -3.8975  6.7775  False\n",
            "              claude-3-haiku@anthropic                   gpt-3.5-turbo@openai     0.88 0.9937 -1.0071  2.7671  False\n",
            "              claude-3-haiku@anthropic                     gpt-4-turbo@openai  -0.4467    1.0 -2.3338  1.4404  False\n",
            "              claude-3-haiku@anthropic                           gpt-4@openai    -0.74 0.9996 -2.6271  1.1471  False\n",
            "              claude-3-haiku@anthropic                          gpt-4o@openai  -0.9333 0.9861 -2.8204  0.9538  False\n",
            "              claude-3-haiku@anthropic              llama-3-70b-chat@anyscale     3.04 0.9298 -2.2975  8.3775  False\n",
            "              claude-3-haiku@anthropic          llama-3-70b-chat@fireworks-ai   0.9757 0.9805 -0.9448  2.8962  False\n",
            "              claude-3-haiku@anthropic               llama-3-8b-chat@anyscale     1.04    1.0 -4.2975  6.3775  False\n",
            "              claude-3-haiku@anthropic           llama-3-8b-chat@fireworks-ai   0.7329 0.9997 -1.1876  2.6534  False\n",
            "              claude-3-haiku@anthropic      mistral-7b-instruct-v0.1@anyscale     1.04    1.0 -4.2975  6.3775  False\n",
            "              claude-3-haiku@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5667    1.0 -1.3204  2.4538  False\n",
            "              claude-3-haiku@anthropic              mistral-large@aws-bedrock   0.2533    1.0 -1.6338  2.1404  False\n",
            "              claude-3-haiku@anthropic               mistral-small@mistral-ai  -0.4733    1.0 -2.3604  1.4138  False\n",
            "              claude-3-haiku@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     0.54    1.0 -4.7975  5.8775  False\n",
            "              claude-3-haiku@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5243    1.0 -2.4448  1.3962  False\n",
            "              claude-3-haiku@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     0.84    1.0 -4.4975  6.1775  False\n",
            "              claude-3-haiku@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4243    1.0 -2.3448  1.4962  False\n",
            "              claude-3-haiku@anthropic                          original_text  -1.0867 0.9217 -2.9738  0.8004  False\n",
            "              claude-3-haiku@anthropic          qwen-2-72b-instruct@deepinfra   1.4257 0.5182 -0.4948  3.3462  False\n",
            "               claude-3-opus@anthropic              claude-3-sonnet@anthropic   2.5067 0.9931 -2.8308  7.8442  False\n",
            "               claude-3-opus@anthropic            claude-3.5-sonnet@anthropic  -0.6867 0.9999 -2.5738  1.2004  False\n",
            "               claude-3-opus@anthropic             gemini-1.5-flash@vertex-ai    -0.62    1.0 -2.5071  1.2671  False\n",
            "               claude-3-opus@anthropic               gemini-1.5-pro@vertex-ai    -0.86 0.9955 -2.7471  1.0271  False\n",
            "               claude-3-opus@anthropic             gemma-2-9b-it@fireworks-ai  -0.8867  0.993 -2.7738  1.0004  False\n",
            "               claude-3-opus@anthropic                gemma-2b-it@together-ai    0.221    1.0 -1.6995  2.1415  False\n",
            "               claude-3-opus@anthropic                   gemma-7b-it@anyscale   1.4067    1.0 -3.9308  6.7442  False\n",
            "               claude-3-opus@anthropic                   gpt-3.5-turbo@openai   0.8467 0.9964 -1.0404  2.7338  False\n",
            "               claude-3-opus@anthropic                     gpt-4-turbo@openai    -0.48    1.0 -2.3671  1.4071  False\n",
            "               claude-3-opus@anthropic                           gpt-4@openai  -0.7733 0.9991 -2.6604  1.1138  False\n",
            "               claude-3-opus@anthropic                          gpt-4o@openai  -0.9667 0.9784 -2.8538  0.9204  False\n",
            "               claude-3-opus@anthropic              llama-3-70b-chat@anyscale   3.0067 0.9373 -2.3308  8.3442  False\n",
            "               claude-3-opus@anthropic          llama-3-70b-chat@fireworks-ai   0.9424 0.9875 -0.9781  2.8629  False\n",
            "               claude-3-opus@anthropic               llama-3-8b-chat@anyscale   1.0067    1.0 -4.3308  6.3442  False\n",
            "               claude-3-opus@anthropic           llama-3-8b-chat@fireworks-ai   0.6995 0.9999  -1.221    2.62  False\n",
            "               claude-3-opus@anthropic      mistral-7b-instruct-v0.1@anyscale   1.0067    1.0 -4.3308  6.3442  False\n",
            "               claude-3-opus@anthropic   mistral-7b-instruct-v0.3@together-ai   0.5333    1.0 -1.3538  2.4204  False\n",
            "               claude-3-opus@anthropic              mistral-large@aws-bedrock     0.22    1.0 -1.6671  2.1071  False\n",
            "               claude-3-opus@anthropic               mistral-small@mistral-ai  -0.5067    1.0 -2.3938  1.3804  False\n",
            "               claude-3-opus@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   0.5067    1.0 -4.8308  5.8442  False\n",
            "               claude-3-opus@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -0.5576    1.0 -2.4781  1.3629  False\n",
            "               claude-3-opus@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   0.8067    1.0 -4.5308  6.1442  False\n",
            "               claude-3-opus@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.4576    1.0 -2.3781  1.4629  False\n",
            "               claude-3-opus@anthropic                          original_text    -1.12 0.8957 -3.0071  0.7671  False\n",
            "               claude-3-opus@anthropic          qwen-2-72b-instruct@deepinfra   1.3924 0.5699 -0.5281  3.3129  False\n",
            "             claude-3-sonnet@anthropic            claude-3.5-sonnet@anthropic  -3.1933 0.8878 -8.5308  2.1442  False\n",
            "             claude-3-sonnet@anthropic             gemini-1.5-flash@vertex-ai  -3.1267 0.9077 -8.4642  2.2108  False\n",
            "             claude-3-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -3.3667 0.8247 -8.7042  1.9708  False\n",
            "             claude-3-sonnet@anthropic             gemma-2-9b-it@fireworks-ai  -3.3933 0.8135 -8.7308  1.9442  False\n",
            "             claude-3-sonnet@anthropic                gemma-2b-it@together-ai  -2.2857 0.9983 -7.6351  3.0637  False\n",
            "             claude-3-sonnet@anthropic                   gemma-7b-it@anyscale     -1.1    1.0 -8.4087  6.2087  False\n",
            "             claude-3-sonnet@anthropic                   gpt-3.5-turbo@openai    -1.66    1.0 -6.9975  3.6775  False\n",
            "             claude-3-sonnet@anthropic                     gpt-4-turbo@openai  -2.9867 0.9414 -8.3242  2.3508  False\n",
            "             claude-3-sonnet@anthropic                           gpt-4@openai    -3.28 0.8583 -8.6175  2.0575  False\n",
            "             claude-3-sonnet@anthropic                          gpt-4o@openai  -3.4733  0.778 -8.8108  1.8642  False\n",
            "             claude-3-sonnet@anthropic              llama-3-70b-chat@anyscale      0.5    1.0 -6.8087  7.8087  False\n",
            "             claude-3-sonnet@anthropic          llama-3-70b-chat@fireworks-ai  -1.5643    1.0 -6.9137  3.7851  False\n",
            "             claude-3-sonnet@anthropic               llama-3-8b-chat@anyscale     -1.5    1.0 -8.8087  5.8087  False\n",
            "             claude-3-sonnet@anthropic           llama-3-8b-chat@fireworks-ai  -1.8071    1.0 -7.1566  3.5423  False\n",
            "             claude-3-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale     -1.5    1.0 -8.8087  5.8087  False\n",
            "             claude-3-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai  -1.9733 0.9998 -7.3108  3.3642  False\n",
            "             claude-3-sonnet@anthropic              mistral-large@aws-bedrock  -2.2867 0.9982 -7.6242  3.0508  False\n",
            "             claude-3-sonnet@anthropic               mistral-small@mistral-ai  -3.0133 0.9358 -8.3508  2.3242  False\n",
            "             claude-3-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             claude-3-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra  -3.0643 0.9257 -8.4137  2.2851  False\n",
            "             claude-3-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale     -1.7    1.0 -9.0087  5.6087  False\n",
            "             claude-3-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock  -2.9643 0.9471 -8.3137  2.3851  False\n",
            "             claude-3-sonnet@anthropic                          original_text  -3.6267 0.7024 -8.9642  1.7108  False\n",
            "             claude-3-sonnet@anthropic          qwen-2-72b-instruct@deepinfra  -1.1143    1.0 -6.4637  4.2351  False\n",
            "           claude-3.5-sonnet@anthropic             gemini-1.5-flash@vertex-ai   0.0667    1.0 -1.8204  1.9538  False\n",
            "           claude-3.5-sonnet@anthropic               gemini-1.5-pro@vertex-ai  -0.1733    1.0 -2.0604  1.7138  False\n",
            "           claude-3.5-sonnet@anthropic             gemma-2-9b-it@fireworks-ai     -0.2    1.0 -2.0871  1.6871  False\n",
            "           claude-3.5-sonnet@anthropic                gemma-2b-it@together-ai   0.9076 0.9924 -1.0129  2.8281  False\n",
            "           claude-3.5-sonnet@anthropic                   gemma-7b-it@anyscale   2.0933 0.9996 -3.2442  7.4308  False\n",
            "           claude-3.5-sonnet@anthropic                   gpt-3.5-turbo@openai   1.5333 0.3236 -0.3538  3.4204  False\n",
            "           claude-3.5-sonnet@anthropic                     gpt-4-turbo@openai   0.2067    1.0 -1.6804  2.0938  False\n",
            "           claude-3.5-sonnet@anthropic                           gpt-4@openai  -0.0867    1.0 -1.9738  1.8004  False\n",
            "           claude-3.5-sonnet@anthropic                          gpt-4o@openai    -0.28    1.0 -2.1671  1.6071  False\n",
            "           claude-3.5-sonnet@anthropic              llama-3-70b-chat@anyscale   3.6933 0.6672 -1.6442  9.0308  False\n",
            "           claude-3.5-sonnet@anthropic          llama-3-70b-chat@fireworks-ai    1.629 0.2419 -0.2915  3.5495  False\n",
            "           claude-3.5-sonnet@anthropic               llama-3-8b-chat@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "           claude-3.5-sonnet@anthropic           llama-3-8b-chat@fireworks-ai   1.3862 0.5795 -0.5343  3.3067  False\n",
            "           claude-3.5-sonnet@anthropic      mistral-7b-instruct-v0.1@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "           claude-3.5-sonnet@anthropic   mistral-7b-instruct-v0.3@together-ai     1.22 0.7884 -0.6671  3.1071  False\n",
            "           claude-3.5-sonnet@anthropic              mistral-large@aws-bedrock   0.9067 0.9905 -0.9804  2.7938  False\n",
            "           claude-3.5-sonnet@anthropic               mistral-small@mistral-ai     0.18    1.0 -1.7071  2.0671  False\n",
            "           claude-3.5-sonnet@anthropic   mixtral-8x22b-instruct-v0.1@anyscale   1.1933    1.0 -4.1442  6.5308  False\n",
            "           claude-3.5-sonnet@anthropic  mixtral-8x22b-instruct-v0.1@deepinfra    0.129    1.0 -1.7915  2.0495  False\n",
            "           claude-3.5-sonnet@anthropic    mixtral-8x7b-instruct-v0.1@anyscale   1.4933    1.0 -3.8442  6.8308  False\n",
            "           claude-3.5-sonnet@anthropic mixtral-8x7b-instruct-v0.1@aws-bedrock    0.229    1.0 -1.6915  2.1495  False\n",
            "           claude-3.5-sonnet@anthropic                          original_text  -0.4333    1.0 -2.3204  1.4538  False\n",
            "           claude-3.5-sonnet@anthropic          qwen-2-72b-instruct@deepinfra    2.079 0.0174  0.1585  3.9995   True\n",
            "            gemini-1.5-flash@vertex-ai               gemini-1.5-pro@vertex-ai    -0.24    1.0 -2.1271  1.6471  False\n",
            "            gemini-1.5-flash@vertex-ai             gemma-2-9b-it@fireworks-ai  -0.2667    1.0 -2.1538  1.6204  False\n",
            "            gemini-1.5-flash@vertex-ai                gemma-2b-it@together-ai    0.841 0.9975 -1.0795  2.7615  False\n",
            "            gemini-1.5-flash@vertex-ai                   gemma-7b-it@anyscale   2.0267 0.9998 -3.3108  7.3642  False\n",
            "            gemini-1.5-flash@vertex-ai                   gpt-3.5-turbo@openai   1.4667 0.4172 -0.4204  3.3538  False\n",
            "            gemini-1.5-flash@vertex-ai                     gpt-4-turbo@openai     0.14    1.0 -1.7471  2.0271  False\n",
            "            gemini-1.5-flash@vertex-ai                           gpt-4@openai  -0.1533    1.0 -2.0404  1.7338  False\n",
            "            gemini-1.5-flash@vertex-ai                          gpt-4o@openai  -0.3467    1.0 -2.2338  1.5404  False\n",
            "            gemini-1.5-flash@vertex-ai              llama-3-70b-chat@anyscale   3.6267 0.7024 -1.7108  8.9642  False\n",
            "            gemini-1.5-flash@vertex-ai          llama-3-70b-chat@fireworks-ai   1.5624 0.3211 -0.3581  3.4829  False\n",
            "            gemini-1.5-flash@vertex-ai               llama-3-8b-chat@anyscale   1.6267    1.0 -3.7108  6.9642  False\n",
            "            gemini-1.5-flash@vertex-ai           llama-3-8b-chat@fireworks-ai   1.3195 0.6811  -0.601    3.24  False\n",
            "            gemini-1.5-flash@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.6267    1.0 -3.7108  6.9642  False\n",
            "            gemini-1.5-flash@vertex-ai   mistral-7b-instruct-v0.3@together-ai   1.1533 0.8648 -0.7338  3.0404  False\n",
            "            gemini-1.5-flash@vertex-ai              mistral-large@aws-bedrock     0.84 0.9968 -1.0471  2.7271  False\n",
            "            gemini-1.5-flash@vertex-ai               mistral-small@mistral-ai   0.1133    1.0 -1.7738  2.0004  False\n",
            "            gemini-1.5-flash@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.1267    1.0 -4.2108  6.4642  False\n",
            "            gemini-1.5-flash@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.0624    1.0 -1.8581  1.9829  False\n",
            "            gemini-1.5-flash@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.4267    1.0 -3.9108  6.7642  False\n",
            "            gemini-1.5-flash@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.1624    1.0 -1.7581  2.0829  False\n",
            "            gemini-1.5-flash@vertex-ai                          original_text     -0.5    1.0 -2.3871  1.3871  False\n",
            "            gemini-1.5-flash@vertex-ai          qwen-2-72b-instruct@deepinfra   2.0124 0.0275  0.0919  3.9329   True\n",
            "              gemini-1.5-pro@vertex-ai             gemma-2-9b-it@fireworks-ai  -0.0267    1.0 -1.9138  1.8604  False\n",
            "              gemini-1.5-pro@vertex-ai                gemma-2b-it@together-ai    1.081 0.9378 -0.8395  3.0015  False\n",
            "              gemini-1.5-pro@vertex-ai                   gemma-7b-it@anyscale   2.2667 0.9984 -3.0708  7.6042  False\n",
            "              gemini-1.5-pro@vertex-ai                   gpt-3.5-turbo@openai   1.7067 0.1435 -0.1804  3.5938  False\n",
            "              gemini-1.5-pro@vertex-ai                     gpt-4-turbo@openai     0.38    1.0 -1.5071  2.2671  False\n",
            "              gemini-1.5-pro@vertex-ai                           gpt-4@openai   0.0867    1.0 -1.8004  1.9738  False\n",
            "              gemini-1.5-pro@vertex-ai                          gpt-4o@openai  -0.1067    1.0 -1.9938  1.7804  False\n",
            "              gemini-1.5-pro@vertex-ai              llama-3-70b-chat@anyscale   3.8667 0.5717 -1.4708  9.2042  False\n",
            "              gemini-1.5-pro@vertex-ai          llama-3-70b-chat@fireworks-ai   1.8024 0.1008 -0.1181  3.7229  False\n",
            "              gemini-1.5-pro@vertex-ai               llama-3-8b-chat@anyscale   1.8667 0.9999 -3.4708  7.2042  False\n",
            "              gemini-1.5-pro@vertex-ai           llama-3-8b-chat@fireworks-ai   1.5595 0.3248  -0.361    3.48  False\n",
            "              gemini-1.5-pro@vertex-ai      mistral-7b-instruct-v0.1@anyscale   1.8667 0.9999 -3.4708  7.2042  False\n",
            "              gemini-1.5-pro@vertex-ai   mistral-7b-instruct-v0.3@together-ai   1.3933 0.5301 -0.4938  3.2804  False\n",
            "              gemini-1.5-pro@vertex-ai              mistral-large@aws-bedrock     1.08 0.9264 -0.8071  2.9671  False\n",
            "              gemini-1.5-pro@vertex-ai               mistral-small@mistral-ai   0.3533    1.0 -1.5338  2.2404  False\n",
            "              gemini-1.5-pro@vertex-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.3667    1.0 -3.9708  6.7042  False\n",
            "              gemini-1.5-pro@vertex-ai  mixtral-8x22b-instruct-v0.1@deepinfra   0.3024    1.0 -1.6181  2.2229  False\n",
            "              gemini-1.5-pro@vertex-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.6667    1.0 -3.6708  7.0042  False\n",
            "              gemini-1.5-pro@vertex-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.4024    1.0 -1.5181  2.3229  False\n",
            "              gemini-1.5-pro@vertex-ai                          original_text    -0.26    1.0 -2.1471  1.6271  False\n",
            "              gemini-1.5-pro@vertex-ai          qwen-2-72b-instruct@deepinfra   2.2524 0.0048  0.3319  4.1729   True\n",
            "            gemma-2-9b-it@fireworks-ai                gemma-2b-it@together-ai   1.1076 0.9205 -0.8129  3.0281  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gemma-7b-it@anyscale   2.2933 0.9981 -3.0442  7.6308  False\n",
            "            gemma-2-9b-it@fireworks-ai                   gpt-3.5-turbo@openai   1.7333 0.1244 -0.1538  3.6204  False\n",
            "            gemma-2-9b-it@fireworks-ai                     gpt-4-turbo@openai   0.4067    1.0 -1.4804  2.2938  False\n",
            "            gemma-2-9b-it@fireworks-ai                           gpt-4@openai   0.1133    1.0 -1.7738  2.0004  False\n",
            "            gemma-2-9b-it@fireworks-ai                          gpt-4o@openai    -0.08    1.0 -1.9671  1.8071  False\n",
            "            gemma-2-9b-it@fireworks-ai              llama-3-70b-chat@anyscale   3.8933 0.5567 -1.4442  9.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai          llama-3-70b-chat@fireworks-ai    1.829 0.0866 -0.0915  3.7495  False\n",
            "            gemma-2-9b-it@fireworks-ai               llama-3-8b-chat@anyscale   1.8933 0.9999 -3.4442  7.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai           llama-3-8b-chat@fireworks-ai   1.5862 0.2913 -0.3343  3.5067  False\n",
            "            gemma-2-9b-it@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   1.8933 0.9999 -3.4442  7.2308  False\n",
            "            gemma-2-9b-it@fireworks-ai   mistral-7b-instruct-v0.3@together-ai     1.42 0.4883 -0.4671  3.3071  False\n",
            "            gemma-2-9b-it@fireworks-ai              mistral-large@aws-bedrock   1.1067 0.9067 -0.7804  2.9938  False\n",
            "            gemma-2-9b-it@fireworks-ai               mistral-small@mistral-ai     0.38    1.0 -1.5071  2.2671  False\n",
            "            gemma-2-9b-it@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.3933    1.0 -3.9442  6.7308  False\n",
            "            gemma-2-9b-it@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra    0.329    1.0 -1.5915  2.2495  False\n",
            "            gemma-2-9b-it@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.6933    1.0 -3.6442  7.0308  False\n",
            "            gemma-2-9b-it@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.429    1.0 -1.4915  2.3495  False\n",
            "            gemma-2-9b-it@fireworks-ai                          original_text  -0.2333    1.0 -2.1204  1.6538  False\n",
            "            gemma-2-9b-it@fireworks-ai          qwen-2-72b-instruct@deepinfra    2.279 0.0039  0.3585  4.1995   True\n",
            "               gemma-2b-it@together-ai                   gemma-7b-it@anyscale   1.1857    1.0 -4.1637  6.5351  False\n",
            "               gemma-2b-it@together-ai                   gpt-3.5-turbo@openai   0.6257    1.0 -1.2948  2.5462  False\n",
            "               gemma-2b-it@together-ai                     gpt-4-turbo@openai   -0.701 0.9999 -2.6215  1.2195  False\n",
            "               gemma-2b-it@together-ai                           gpt-4@openai  -0.9943 0.9755 -2.9148  0.9262  False\n",
            "               gemma-2b-it@together-ai                          gpt-4o@openai  -1.1876 0.8507 -3.1081  0.7329  False\n",
            "               gemma-2b-it@together-ai              llama-3-70b-chat@anyscale   2.7857 0.9737 -2.5637  8.1351  False\n",
            "               gemma-2b-it@together-ai          llama-3-70b-chat@fireworks-ai   0.7214 0.9998 -1.2319  2.6748  False\n",
            "               gemma-2b-it@together-ai               llama-3-8b-chat@anyscale   0.7857    1.0 -4.5637  6.1351  False\n",
            "               gemma-2b-it@together-ai           llama-3-8b-chat@fireworks-ai   0.4786    1.0 -1.4748  2.4319  False\n",
            "               gemma-2b-it@together-ai      mistral-7b-instruct-v0.1@anyscale   0.7857    1.0 -4.5637  6.1351  False\n",
            "               gemma-2b-it@together-ai   mistral-7b-instruct-v0.3@together-ai   0.3124    1.0 -1.6081  2.2329  False\n",
            "               gemma-2b-it@together-ai              mistral-large@aws-bedrock   -0.001    1.0 -1.9215  1.9195  False\n",
            "               gemma-2b-it@together-ai               mistral-small@mistral-ai  -0.7276 0.9998 -2.6481  1.1929  False\n",
            "               gemma-2b-it@together-ai   mixtral-8x22b-instruct-v0.1@anyscale   0.2857    1.0 -5.0637  5.6351  False\n",
            "               gemma-2b-it@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.7786 0.9994 -2.7319  1.1748  False\n",
            "               gemma-2b-it@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.5857    1.0 -4.7637  5.9351  False\n",
            "               gemma-2b-it@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.6786 0.9999 -2.6319  1.2748  False\n",
            "               gemma-2b-it@together-ai                          original_text   -1.341 0.6491 -3.2615  0.5795  False\n",
            "               gemma-2b-it@together-ai          qwen-2-72b-instruct@deepinfra   1.1714 0.8854 -0.7819  3.1248  False\n",
            "                  gemma-7b-it@anyscale                   gpt-3.5-turbo@openai    -0.56    1.0 -5.8975  4.7775  False\n",
            "                  gemma-7b-it@anyscale                     gpt-4-turbo@openai  -1.8867 0.9999 -7.2242  3.4508  False\n",
            "                  gemma-7b-it@anyscale                           gpt-4@openai    -2.18 0.9992 -7.5175  3.1575  False\n",
            "                  gemma-7b-it@anyscale                          gpt-4o@openai  -2.3733 0.9968 -7.7108  2.9642  False\n",
            "                  gemma-7b-it@anyscale              llama-3-70b-chat@anyscale      1.6    1.0 -5.7087  8.9087  False\n",
            "                  gemma-7b-it@anyscale          llama-3-70b-chat@fireworks-ai  -0.4643    1.0 -5.8137  4.8851  False\n",
            "                  gemma-7b-it@anyscale               llama-3-8b-chat@anyscale     -0.4    1.0 -7.7087  6.9087  False\n",
            "                  gemma-7b-it@anyscale           llama-3-8b-chat@fireworks-ai  -0.7071    1.0 -6.0566  4.6423  False\n",
            "                  gemma-7b-it@anyscale      mistral-7b-instruct-v0.1@anyscale     -0.4    1.0 -7.7087  6.9087  False\n",
            "                  gemma-7b-it@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.8733    1.0 -6.2108  4.4642  False\n",
            "                  gemma-7b-it@anyscale              mistral-large@aws-bedrock  -1.1867    1.0 -6.5242  4.1508  False\n",
            "                  gemma-7b-it@anyscale               mistral-small@mistral-ai  -1.9133 0.9999 -7.2508  3.4242  False\n",
            "                  gemma-7b-it@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.9    1.0 -8.2087  6.4087  False\n",
            "                  gemma-7b-it@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.9643 0.9999 -7.3137  3.3851  False\n",
            "                  gemma-7b-it@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.6    1.0 -7.9087  6.7087  False\n",
            "                  gemma-7b-it@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.8643 0.9999 -7.2137  3.4851  False\n",
            "                  gemma-7b-it@anyscale                          original_text  -2.5267 0.9922 -7.8642  2.8108  False\n",
            "                  gemma-7b-it@anyscale          qwen-2-72b-instruct@deepinfra  -0.0143    1.0 -5.3637  5.3351  False\n",
            "                  gpt-3.5-turbo@openai                     gpt-4-turbo@openai  -1.3267 0.6351 -3.2138  0.5604  False\n",
            "                  gpt-3.5-turbo@openai                           gpt-4@openai    -1.62 0.2212 -3.5071  0.2671  False\n",
            "                  gpt-3.5-turbo@openai                          gpt-4o@openai  -1.8133 0.0788 -3.7004  0.0738  False\n",
            "                  gpt-3.5-turbo@openai              llama-3-70b-chat@anyscale     2.16 0.9993 -3.1775  7.4975  False\n",
            "                  gpt-3.5-turbo@openai          llama-3-70b-chat@fireworks-ai   0.0957    1.0 -1.8248  2.0162  False\n",
            "                  gpt-3.5-turbo@openai               llama-3-8b-chat@anyscale     0.16    1.0 -5.1775  5.4975  False\n",
            "                  gpt-3.5-turbo@openai           llama-3-8b-chat@fireworks-ai  -0.1471    1.0 -2.0676  1.7734  False\n",
            "                  gpt-3.5-turbo@openai      mistral-7b-instruct-v0.1@anyscale     0.16    1.0 -5.1775  5.4975  False\n",
            "                  gpt-3.5-turbo@openai   mistral-7b-instruct-v0.3@together-ai  -0.3133    1.0 -2.2004  1.5738  False\n",
            "                  gpt-3.5-turbo@openai              mistral-large@aws-bedrock  -0.6267    1.0 -2.5138  1.2604  False\n",
            "                  gpt-3.5-turbo@openai               mistral-small@mistral-ai  -1.3533 0.5933 -3.2404  0.5338  False\n",
            "                  gpt-3.5-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale    -0.34    1.0 -5.6775  4.9975  False\n",
            "                  gpt-3.5-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.4043 0.5514 -3.3248  0.5162  False\n",
            "                  gpt-3.5-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale    -0.04    1.0 -5.3775  5.2975  False\n",
            "                  gpt-3.5-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.3043 0.7034 -3.2248  0.6162  False\n",
            "                  gpt-3.5-turbo@openai                          original_text  -1.9667 0.0296 -3.8538 -0.0796   True\n",
            "                  gpt-3.5-turbo@openai          qwen-2-72b-instruct@deepinfra   0.5457    1.0 -1.3748  2.4662  False\n",
            "                    gpt-4-turbo@openai                           gpt-4@openai  -0.2933    1.0 -2.1804  1.5938  False\n",
            "                    gpt-4-turbo@openai                          gpt-4o@openai  -0.4867    1.0 -2.3738  1.4004  False\n",
            "                    gpt-4-turbo@openai              llama-3-70b-chat@anyscale   3.4867 0.7718 -1.8508  8.8242  False\n",
            "                    gpt-4-turbo@openai          llama-3-70b-chat@fireworks-ai   1.4224 0.5233 -0.4981  3.3429  False\n",
            "                    gpt-4-turbo@openai               llama-3-8b-chat@anyscale   1.4867    1.0 -3.8508  6.8242  False\n",
            "                    gpt-4-turbo@openai           llama-3-8b-chat@fireworks-ai   1.1795  0.859  -0.741     3.1  False\n",
            "                    gpt-4-turbo@openai      mistral-7b-instruct-v0.1@anyscale   1.4867    1.0 -3.8508  6.8242  False\n",
            "                    gpt-4-turbo@openai   mistral-7b-instruct-v0.3@together-ai   1.0133 0.9625 -0.8738  2.9004  False\n",
            "                    gpt-4-turbo@openai              mistral-large@aws-bedrock      0.7 0.9998 -1.1871  2.5871  False\n",
            "                    gpt-4-turbo@openai               mistral-small@mistral-ai  -0.0267    1.0 -1.9138  1.8604  False\n",
            "                    gpt-4-turbo@openai   mixtral-8x22b-instruct-v0.1@anyscale   0.9867    1.0 -4.3508  6.3242  False\n",
            "                    gpt-4-turbo@openai  mixtral-8x22b-instruct-v0.1@deepinfra  -0.0776    1.0 -1.9981  1.8429  False\n",
            "                    gpt-4-turbo@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.2867    1.0 -4.0508  6.6242  False\n",
            "                    gpt-4-turbo@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.0224    1.0 -1.8981  1.9429  False\n",
            "                    gpt-4-turbo@openai                          original_text    -0.64    1.0 -2.5271  1.2471  False\n",
            "                    gpt-4-turbo@openai          qwen-2-72b-instruct@deepinfra   1.8724 0.0672 -0.0481  3.7929  False\n",
            "                          gpt-4@openai                          gpt-4o@openai  -0.1933    1.0 -2.0804  1.6938  False\n",
            "                          gpt-4@openai              llama-3-70b-chat@anyscale     3.78 0.6199 -1.5575  9.1175  False\n",
            "                          gpt-4@openai          llama-3-70b-chat@fireworks-ai   1.7157   0.16 -0.2048  3.6362  False\n",
            "                          gpt-4@openai               llama-3-8b-chat@anyscale     1.78    1.0 -3.5575  7.1175  False\n",
            "                          gpt-4@openai           llama-3-8b-chat@fireworks-ai   1.4729 0.4464 -0.4476  3.3934  False\n",
            "                          gpt-4@openai      mistral-7b-instruct-v0.1@anyscale     1.78    1.0 -3.5575  7.1175  False\n",
            "                          gpt-4@openai   mistral-7b-instruct-v0.3@together-ai   1.3067 0.6658 -0.5804  3.1938  False\n",
            "                          gpt-4@openai              mistral-large@aws-bedrock   0.9933 0.9702 -0.8938  2.8804  False\n",
            "                          gpt-4@openai               mistral-small@mistral-ai   0.2667    1.0 -1.6204  2.1538  False\n",
            "                          gpt-4@openai   mixtral-8x22b-instruct-v0.1@anyscale     1.28    1.0 -4.0575  6.6175  False\n",
            "                          gpt-4@openai  mixtral-8x22b-instruct-v0.1@deepinfra   0.2157    1.0 -1.7048  2.1362  False\n",
            "                          gpt-4@openai    mixtral-8x7b-instruct-v0.1@anyscale     1.58    1.0 -3.7575  6.9175  False\n",
            "                          gpt-4@openai mixtral-8x7b-instruct-v0.1@aws-bedrock   0.3157    1.0 -1.6048  2.2362  False\n",
            "                          gpt-4@openai                          original_text  -0.3467    1.0 -2.2338  1.5404  False\n",
            "                          gpt-4@openai          qwen-2-72b-instruct@deepinfra   2.1657 0.0093  0.2452  4.0862   True\n",
            "                         gpt-4o@openai              llama-3-70b-chat@anyscale   3.9733 0.5121 -1.3642  9.3108  False\n",
            "                         gpt-4o@openai          llama-3-70b-chat@fireworks-ai    1.909 0.0537 -0.0115  3.8295  False\n",
            "                         gpt-4o@openai               llama-3-8b-chat@anyscale   1.9733 0.9998 -3.3642  7.3108  False\n",
            "                         gpt-4o@openai           llama-3-8b-chat@fireworks-ai   1.6662 0.2039 -0.2543  3.5867  False\n",
            "                         gpt-4o@openai      mistral-7b-instruct-v0.1@anyscale   1.9733 0.9998 -3.3642  7.3108  False\n",
            "                         gpt-4o@openai   mistral-7b-instruct-v0.3@together-ai      1.5  0.369 -0.3871  3.3871  False\n",
            "                         gpt-4o@openai              mistral-large@aws-bedrock   1.1867 0.8289 -0.7004  3.0738  False\n",
            "                         gpt-4o@openai               mistral-small@mistral-ai     0.46    1.0 -1.4271  2.3471  False\n",
            "                         gpt-4o@openai   mixtral-8x22b-instruct-v0.1@anyscale   1.4733    1.0 -3.8642  6.8108  False\n",
            "                         gpt-4o@openai  mixtral-8x22b-instruct-v0.1@deepinfra    0.409    1.0 -1.5115  2.3295  False\n",
            "                         gpt-4o@openai    mixtral-8x7b-instruct-v0.1@anyscale   1.7733    1.0 -3.5642  7.1108  False\n",
            "                         gpt-4o@openai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.509    1.0 -1.4115  2.4295  False\n",
            "                         gpt-4o@openai                          original_text  -0.1533    1.0 -2.0404  1.7338  False\n",
            "                         gpt-4o@openai          qwen-2-72b-instruct@deepinfra    2.359  0.002  0.4385  4.2795   True\n",
            "             llama-3-70b-chat@anyscale          llama-3-70b-chat@fireworks-ai  -2.0643 0.9997 -7.4137  3.2851  False\n",
            "             llama-3-70b-chat@anyscale               llama-3-8b-chat@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             llama-3-70b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -2.3071  0.998 -7.6566  3.0423  False\n",
            "             llama-3-70b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale     -2.0    1.0 -9.3087  5.3087  False\n",
            "             llama-3-70b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -2.4733 0.9942 -7.8108  2.8642  False\n",
            "             llama-3-70b-chat@anyscale              mistral-large@aws-bedrock  -2.7867 0.9729 -8.1242  2.5508  False\n",
            "             llama-3-70b-chat@anyscale               mistral-small@mistral-ai  -3.5133 0.7592 -8.8508  1.8242  False\n",
            "             llama-3-70b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -2.5    1.0 -9.8087  4.8087  False\n",
            "             llama-3-70b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -3.5643 0.7382 -8.9137  1.7851  False\n",
            "             llama-3-70b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -2.2    1.0 -9.5087  5.1087  False\n",
            "             llama-3-70b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -3.4643 0.7857 -8.8137  1.8851  False\n",
            "             llama-3-70b-chat@anyscale                          original_text  -4.1267 0.4286 -9.4642  1.2108  False\n",
            "             llama-3-70b-chat@anyscale          qwen-2-72b-instruct@deepinfra  -1.6143    1.0 -6.9637  3.7351  False\n",
            "         llama-3-70b-chat@fireworks-ai               llama-3-8b-chat@anyscale   0.0643    1.0 -5.2851  5.4137  False\n",
            "         llama-3-70b-chat@fireworks-ai           llama-3-8b-chat@fireworks-ai  -0.2429    1.0 -2.1962  1.7105  False\n",
            "         llama-3-70b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.0643    1.0 -5.2851  5.4137  False\n",
            "         llama-3-70b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai   -0.409    1.0 -2.3295  1.5115  False\n",
            "         llama-3-70b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.7224 0.9998 -2.6429  1.1981  False\n",
            "         llama-3-70b-chat@fireworks-ai               mistral-small@mistral-ai   -1.449 0.4823 -3.3695  0.4715  False\n",
            "         llama-3-70b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.4357    1.0 -5.7851  4.9137  False\n",
            "         llama-3-70b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra     -1.5 0.4435 -3.4533  0.4533  False\n",
            "         llama-3-70b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale  -0.1357    1.0 -5.4851  5.2137  False\n",
            "         llama-3-70b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock     -1.4 0.5946 -3.3533  0.5533  False\n",
            "         llama-3-70b-chat@fireworks-ai                          original_text  -2.0624 0.0195 -3.9829 -0.1419   True\n",
            "         llama-3-70b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra     0.45    1.0 -1.5033  2.4033  False\n",
            "              llama-3-8b-chat@anyscale           llama-3-8b-chat@fireworks-ai  -0.3071    1.0 -5.6566  5.0423  False\n",
            "              llama-3-8b-chat@anyscale      mistral-7b-instruct-v0.1@anyscale      0.0    1.0 -7.3087  7.3087  False\n",
            "              llama-3-8b-chat@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.4733    1.0 -5.8108  4.8642  False\n",
            "              llama-3-8b-chat@anyscale              mistral-large@aws-bedrock  -0.7867    1.0 -6.1242  4.5508  False\n",
            "              llama-3-8b-chat@anyscale               mistral-small@mistral-ai  -1.5133    1.0 -6.8508  3.8242  False\n",
            "              llama-3-8b-chat@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.5    1.0 -7.8087  6.8087  False\n",
            "              llama-3-8b-chat@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.5643    1.0 -6.9137  3.7851  False\n",
            "              llama-3-8b-chat@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.2    1.0 -7.5087  7.1087  False\n",
            "              llama-3-8b-chat@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.4643    1.0 -6.8137  3.8851  False\n",
            "              llama-3-8b-chat@anyscale                          original_text  -2.1267 0.9994 -7.4642  3.2108  False\n",
            "              llama-3-8b-chat@anyscale          qwen-2-72b-instruct@deepinfra   0.3857    1.0 -4.9637  5.7351  False\n",
            "          llama-3-8b-chat@fireworks-ai      mistral-7b-instruct-v0.1@anyscale   0.3071    1.0 -5.0423  5.6566  False\n",
            "          llama-3-8b-chat@fireworks-ai   mistral-7b-instruct-v0.3@together-ai  -0.1662    1.0 -2.0867  1.7543  False\n",
            "          llama-3-8b-chat@fireworks-ai              mistral-large@aws-bedrock  -0.4795    1.0    -2.4   1.441  False\n",
            "          llama-3-8b-chat@fireworks-ai               mistral-small@mistral-ai  -1.2062 0.8305 -3.1267  0.7143  False\n",
            "          llama-3-8b-chat@fireworks-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.1929    1.0 -5.5423  5.1566  False\n",
            "          llama-3-8b-chat@fireworks-ai  mixtral-8x22b-instruct-v0.1@deepinfra  -1.2571 0.7953 -3.2105  0.6962  False\n",
            "          llama-3-8b-chat@fireworks-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.1071    1.0 -5.2423  5.4566  False\n",
            "          llama-3-8b-chat@fireworks-ai mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.1571 0.8975 -3.1105  0.7962  False\n",
            "          llama-3-8b-chat@fireworks-ai                          original_text  -1.8195 0.0915   -3.74   0.101  False\n",
            "          llama-3-8b-chat@fireworks-ai          qwen-2-72b-instruct@deepinfra   0.6929 0.9999 -1.2605  2.6462  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mistral-7b-instruct-v0.3@together-ai  -0.4733    1.0 -5.8108  4.8642  False\n",
            "     mistral-7b-instruct-v0.1@anyscale              mistral-large@aws-bedrock  -0.7867    1.0 -6.1242  4.5508  False\n",
            "     mistral-7b-instruct-v0.1@anyscale               mistral-small@mistral-ai  -1.5133    1.0 -6.8508  3.8242  False\n",
            "     mistral-7b-instruct-v0.1@anyscale   mixtral-8x22b-instruct-v0.1@anyscale     -0.5    1.0 -7.8087  6.8087  False\n",
            "     mistral-7b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.5643    1.0 -6.9137  3.7851  False\n",
            "     mistral-7b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale     -0.2    1.0 -7.5087  7.1087  False\n",
            "     mistral-7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.4643    1.0 -6.8137  3.8851  False\n",
            "     mistral-7b-instruct-v0.1@anyscale                          original_text  -2.1267 0.9994 -7.4642  3.2108  False\n",
            "     mistral-7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.3857    1.0 -4.9637  5.7351  False\n",
            "  mistral-7b-instruct-v0.3@together-ai              mistral-large@aws-bedrock  -0.3133    1.0 -2.2004  1.5738  False\n",
            "  mistral-7b-instruct-v0.3@together-ai               mistral-small@mistral-ai    -1.04 0.9501 -2.9271  0.8471  False\n",
            "  mistral-7b-instruct-v0.3@together-ai   mixtral-8x22b-instruct-v0.1@anyscale  -0.0267    1.0 -5.3642  5.3108  False\n",
            "  mistral-7b-instruct-v0.3@together-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -1.091 0.9317 -3.0115  0.8295  False\n",
            "  mistral-7b-instruct-v0.3@together-ai    mixtral-8x7b-instruct-v0.1@anyscale   0.2733    1.0 -5.0642  5.6108  False\n",
            "  mistral-7b-instruct-v0.3@together-ai mixtral-8x7b-instruct-v0.1@aws-bedrock   -0.991 0.9765 -2.9115  0.9295  False\n",
            "  mistral-7b-instruct-v0.3@together-ai                          original_text  -1.6533 0.1885 -3.5404  0.2338  False\n",
            "  mistral-7b-instruct-v0.3@together-ai          qwen-2-72b-instruct@deepinfra    0.859 0.9965 -1.0615  2.7795  False\n",
            "             mistral-large@aws-bedrock               mistral-small@mistral-ai  -0.7267 0.9997 -2.6138  1.1604  False\n",
            "             mistral-large@aws-bedrock   mixtral-8x22b-instruct-v0.1@anyscale   0.2867    1.0 -5.0508  5.6242  False\n",
            "             mistral-large@aws-bedrock  mixtral-8x22b-instruct-v0.1@deepinfra  -0.7776 0.9993 -2.6981  1.1429  False\n",
            "             mistral-large@aws-bedrock    mixtral-8x7b-instruct-v0.1@anyscale   0.5867    1.0 -4.7508  5.9242  False\n",
            "             mistral-large@aws-bedrock mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.6776 0.9999 -2.5981  1.2429  False\n",
            "             mistral-large@aws-bedrock                          original_text    -1.34 0.6143 -3.2271  0.5471  False\n",
            "             mistral-large@aws-bedrock          qwen-2-72b-instruct@deepinfra   1.1724 0.8661 -0.7481  3.0929  False\n",
            "              mistral-small@mistral-ai   mixtral-8x22b-instruct-v0.1@anyscale   1.0133    1.0 -4.3242  6.3508  False\n",
            "              mistral-small@mistral-ai  mixtral-8x22b-instruct-v0.1@deepinfra   -0.051    1.0 -1.9715  1.8695  False\n",
            "              mistral-small@mistral-ai    mixtral-8x7b-instruct-v0.1@anyscale   1.3133    1.0 -4.0242  6.6508  False\n",
            "              mistral-small@mistral-ai mixtral-8x7b-instruct-v0.1@aws-bedrock    0.049    1.0 -1.8715  1.9695  False\n",
            "              mistral-small@mistral-ai                          original_text  -0.6133    1.0 -2.5004  1.2738  False\n",
            "              mistral-small@mistral-ai          qwen-2-72b-instruct@deepinfra    1.899 0.0571 -0.0215  3.8195  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale  mixtral-8x22b-instruct-v0.1@deepinfra  -1.0643    1.0 -6.4137  4.2851  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale    mixtral-8x7b-instruct-v0.1@anyscale      0.3    1.0 -7.0087  7.6087  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -0.9643    1.0 -6.3137  4.3851  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale                          original_text  -1.6267    1.0 -6.9642  3.7108  False\n",
            "  mixtral-8x22b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.8857    1.0 -4.4637  6.2351  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra    mixtral-8x7b-instruct-v0.1@anyscale   1.3643    1.0 -3.9851  6.7137  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra mixtral-8x7b-instruct-v0.1@aws-bedrock      0.1    1.0 -1.8533  2.0533  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra                          original_text  -0.5624    1.0 -2.4829  1.3581  False\n",
            " mixtral-8x22b-instruct-v0.1@deepinfra          qwen-2-72b-instruct@deepinfra     1.95  0.051 -0.0033  3.9033  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale mixtral-8x7b-instruct-v0.1@aws-bedrock  -1.2643    1.0 -6.6137  4.0851  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale                          original_text  -1.9267 0.9999 -7.2642  3.4108  False\n",
            "   mixtral-8x7b-instruct-v0.1@anyscale          qwen-2-72b-instruct@deepinfra   0.5857    1.0 -4.7637  5.9351  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                          original_text  -0.6624    1.0 -2.5829  1.2581  False\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock          qwen-2-72b-instruct@deepinfra     1.85 0.0918 -0.1033  3.8033  False\n",
            "                         original_text          qwen-2-72b-instruct@deepinfra   2.5124 0.0005  0.5919  4.4329   True\n",
            "--------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}